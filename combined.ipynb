{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6475e29c9be8488c984df09941f83bb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_60fdf7e49d3d4681807d4ded88d7425f",
              "IPY_MODEL_597db6322df145f2888149100338d766",
              "IPY_MODEL_80bd4d39a43d4818aa3ccfb8b66fadb0"
            ],
            "layout": "IPY_MODEL_3df19f1fa38c4bf79591b40b283e5008"
          }
        },
        "60fdf7e49d3d4681807d4ded88d7425f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2372001d365b42c9acacb0c12f36def2",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_d689d108212644ddabe6c607aa66afd6",
            "value": "Crawling‚Äá+‚ÄáEncoding:‚Äá‚Äá‚Äá0%"
          }
        },
        "597db6322df145f2888149100338d766": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44f91466802d4b64bf8df8b3b0db0f16",
            "max": 26555,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8134b48a8438486babd452826d9b1d76",
            "value": 1
          }
        },
        "80bd4d39a43d4818aa3ccfb8b66fadb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68808ec8c4a14d8e881c75f8b22596c6",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_1238c2054ca34ae3802ca526c1411abf",
            "value": "‚Äá1/26555‚Äá[00:08&lt;10:36:28,‚Äá‚Äá1.44s/it]"
          }
        },
        "3df19f1fa38c4bf79591b40b283e5008": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2372001d365b42c9acacb0c12f36def2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d689d108212644ddabe6c607aa66afd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44f91466802d4b64bf8df8b3b0db0f16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8134b48a8438486babd452826d9b1d76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "68808ec8c4a14d8e881c75f8b22596c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1238c2054ca34ae3802ca526c1411abf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# News Article Similarity Pipeline\n",
        "## Siamese Embedding + 5W1H Extraction\n",
        "\n",
        "---\n",
        "\n",
        "## üìã Overview\n",
        "\n",
        "This pipeline performs two major analytical tasks on news articles:\n",
        "\n",
        "### 1. **Semantic Similarity Analysis**\n",
        "Extracts and compares the first two paragraphs of news articles using:\n",
        "- **SentenceTransformer** (MiniLM) embeddings\n",
        "- **Cosine similarity** metrics\n",
        "\n",
        "### 2. **5W1H Entity Extraction**\n",
        "Run manually in terminal using\n",
        "\n",
        "`java -Xmx4g -cp \"$(echo $HOME/.stanfordnlp_resources/stanford-corenlp-4.5.7/*.jar | tr ' ' ':')\" \\\n",
        "edu.stanford.nlp.pipeline.StanfordCoreNLPServer \\\n",
        "-port 9010 -timeout 500000 \\\n",
        "-annotators tokenize,ssplit,pos,lemma,ner,parse,depparse,coref \\\n",
        "-preload tokenize,ssplit,pos,lemma,ner,parse,depparse,coref \\\n",
        "-coref.algorithm neural\n",
        "`\n",
        "\n",
        "Extracts journalism's fundamental questions from article titles:\n",
        "- **Who** - People/Organizations involved\n",
        "- **What** - Events/Actions that occurred\n",
        "- **When** - Temporal information\n",
        "- **Where** - Locations/Places\n",
        "- **Why** - Reasons/Motivations\n",
        "- **How** - Methods/Processes\n",
        "\n",
        "Uses **Giveme5W1H** library with **Stanford CoreNLP Server** backend.\n",
        "---\n",
        "\n",
        "## üìö Key Libraries\n",
        "\n",
        "- **sentence-transformers**: Neural sentence embeddings\n",
        "- **trafilatura**: Web scraping & text extraction\n",
        "- **Giveme5W1H**: 5W1H entity extraction\n",
        "- **Stanford CoreNLP**: NLP backend for entity recognition\n",
        "- **scikit-learn**: Cosine similarity computation\n"
      ],
      "metadata": {
        "id": "ihqGgWh3ilzG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dependencies and Imports (Siamese)"
      ],
      "metadata": {
        "id": "iYbOgef5mL2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install sentence-transformers trafilatura readability-lxml bs4 lxml html5lib tqdm\n",
        "!pip -q install giveme5w1h geopy"
      ],
      "metadata": {
        "id": "HnEuHGK0p2Mp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "957539d1-ed48-419f-b719-6f23b91ec4c6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m837.9/837.9 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m315.5/315.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m274.7/274.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m235.8/235.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m74.6/74.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m264.7/264.7 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m608.4/608.4 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for giveme5w1h (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pycorenlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for typing (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ----------------------------\n",
        "#  Import required libraries\n",
        "# ----------------------------\n",
        "import re, math, time, sys, warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from urllib.parse import urlparse\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import trafilatura\n",
        "from tqdm.auto import tqdm\n",
        "from sentence_transformers import SentenceTransformer"
      ],
      "metadata": {
        "id": "HOJdPus3iYBx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Helper functions\n",
        "\n",
        "> Add blockquote\n",
        "\n"
      ],
      "metadata": {
        "id": "SvIZqLaQmAVk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ----------------------------\n",
        "#  Helper: URL validation\n",
        "# ----------------------------\n",
        "HEADERS = {\"User-Agent\": \"Mozilla/5.0 (compatible; NewsSimilarityBot/1.0; +https://example.org/bot)\"}\n",
        "\n",
        "def is_valid_url(u: str) -> bool:\n",
        "    \"\"\"Check if a given string is a valid HTTP/HTTPS URL.\"\"\"\n",
        "    if not isinstance(u, str) or not u.strip():\n",
        "        return False\n",
        "    p = urlparse(u.strip())\n",
        "    return p.scheme in {\"http\", \"https\"} and bool(p.netloc)\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "#  Extract first two paragraphs from HTML\n",
        "# ----------------------------\n",
        "def first_two_paragraphs_from_html(html: str):\n",
        "    \"\"\"Return the first two meaningful paragraphs from a raw HTML document.\"\"\"\n",
        "    soup = BeautifulSoup(html, \"lxml\")\n",
        "    root = soup.find(\"article\") or soup.find(\"main\") or soup\n",
        "    paras = []\n",
        "    for p in root.find_all(\"p\"):\n",
        "        txt = re.sub(r\"\\s+\", \" \", p.get_text(\" \", strip=True)).strip()\n",
        "        if len(txt) >= 40:  # ignore very short boilerplate text\n",
        "            paras.append(txt)\n",
        "        if len(paras) >= 2:\n",
        "            break\n",
        "    # fallback: if not enough paragraphs found\n",
        "    if len(paras) < 2:\n",
        "        paras = [re.sub(r\"\\s+\", \" \", p.get_text(\" \", strip=True)).strip()\n",
        "                 for p in root.find_all(\"p\") if p.get_text(strip=True)]\n",
        "        paras = [x for x in paras if x][:2]\n",
        "    p1 = paras[0] if len(paras) > 0 else None\n",
        "    p2 = paras[1] if len(paras) > 1 else None\n",
        "    return p1, p2\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "#  Fetch paragraphs (Trafilatura ‚Üí BeautifulSoup fallback)\n",
        "# ----------------------------\n",
        "def fetch_first_two_paragraphs(url: str, timeout=12):\n",
        "    \"\"\"\n",
        "    Try extracting readable text via Trafilatura first,\n",
        "    then fall back to raw HTML parsing using BeautifulSoup.\n",
        "    Always returns (p1, p2, status)\n",
        "    where status ‚àà {'ok','invalid_url','fetch_error','no_content'}.\n",
        "    \"\"\"\n",
        "    if not is_valid_url(url):\n",
        "        return None, None, \"invalid_url\"\n",
        "\n",
        "    try:\n",
        "        downloaded = trafilatura.fetch_url(url, no_ssl=True)\n",
        "        if downloaded:\n",
        "            text = trafilatura.extract(downloaded, include_comments=False, include_tables=False)\n",
        "            if text:\n",
        "                blocks = [b.strip() for b in re.split(r\"\\n\\s*\\n\", text) if b.strip()]\n",
        "                blocks = [b for b in blocks if len(b) >= 40]\n",
        "                p1 = blocks[0] if len(blocks) > 0 else None\n",
        "                p2 = blocks[1] if len(blocks) > 1 else None\n",
        "                if p1 or p2:\n",
        "                    return p1, p2, \"ok\"\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Trafilatura error for {url}: {e}\")\n",
        "\n",
        "    try:\n",
        "        r = requests.get(url, headers=HEADERS, timeout=timeout)\n",
        "        if r.ok and r.text:\n",
        "            p1, p2 = first_two_paragraphs_from_html(r.text)\n",
        "            if p1 or p2:\n",
        "                return p1, p2, \"ok\"\n",
        "            return None, None, \"no_content\"\n",
        "        return None, None, \"fetch_error\"\n",
        "    except (requests.Timeout, requests.ConnectionError) as e:\n",
        "        print(f\"‚ö° Skipping slow/unreachable URL: {url} ({e})\")\n",
        "        return None, None, \"fetch_error\"\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Unknown error fetching {url}: {e}\")\n",
        "        return None, None, \"fetch_error\"\n",
        "\n",
        "    # Just in case no branch above runs\n",
        "    return None, None, \"fetch_error\"\n"
      ],
      "metadata": {
        "id": "6BYGxWGLib6L"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Embeddings and similarity *functions*"
      ],
      "metadata": {
        "id": "25Ixn5rkmG-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ----------------------------\n",
        "#  Initialize embedding model\n",
        "# ----------------------------\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "def embed(text: str):\n",
        "    \"\"\"Return a unit-normalized embedding for text.\"\"\"\n",
        "    if not isinstance(text, str) or not text.strip():\n",
        "        return None\n",
        "    v = model.encode([text.strip()], normalize_embeddings=True)[0]\n",
        "    return v\n",
        "\n",
        "def cosine_sim(v1, v2):\n",
        "    \"\"\"Compute cosine similarity between two vectors.\"\"\"\n",
        "    if v1 is None or v2 is None:\n",
        "        return np.nan\n",
        "    return float(np.dot(v1, v2))"
      ],
      "metadata": {
        "id": "Omf41tQ-ifb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "91666b72-2098-4650-dc13-4a5ba3c71f05"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'SentenceTransformer' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2551268044.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#  Initialize embedding model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"all-MiniLM-L6-v2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'SentenceTransformer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Load and peek dataset"
      ],
      "metadata": {
        "id": "qNS13vINma0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kudjhnunYwRd",
        "outputId": "b172b74a-0e3a-4e63-8ac4-6a8101b146c0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ================================================================\n",
        "#  STEP 1: Load Dataset\n",
        "# ================================================================\n",
        "# df = pd.read_csv('drive/MyDrive/zenodo_with_url_exists.csv')\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# read from the same directory as combined.ipynb / combined.py\n",
        "base_dir = os.path.dirname(os.path.abspath(__file__)) if \"__file__\" in globals() else os.getcwd()\n",
        "csv_path = os.path.join(base_dir, \"zenodo_with_url_exists.csv\")\n",
        "\n",
        "if not os.path.exists(csv_path):\n",
        "    raise FileNotFoundError(f\"‚ùå Dataset not found: {csv_path}\")\n",
        "\n",
        "df = pd.read_csv(csv_path)\n",
        "print(f\"‚úÖ Loaded {len(df)} rows from {csv_path}\")\n",
        "# Basic info and sanity check\n",
        "print(f\"‚úÖ Loaded {len(df)} rows from zenodo_with_url_exists.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7uc_MIEpz2T",
        "outputId": "5f4e0895-be2a-48cc-fa5a-c191ba3818bb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Loaded 26555 rows from /content/zenodo_with_url_exists.csv\n",
            "‚úÖ Loaded 26555 rows from zenodo_with_url_exists.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "id": "N2L9MpZp4_pJ",
        "outputId": "84b899c6-d030-42f9-8222-72e51293a53a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0        content.pair_id  content.similarity  \\\n",
              "0           0  1484188922_1484188392            0.141053   \n",
              "1           1  1484299489_1484110209            0.243056   \n",
              "2           2  1484188635_1484299664            0.097911   \n",
              "3           3  1484188331_1484347237            0.129065   \n",
              "4           4  1484010809_1484223087            0.188465   \n",
              "\n",
              "                                        content.url1  \\\n",
              "0  https://www.marshallindependent.com/news/local...   \n",
              "1  https://www.washingtonpost.com/local/winning-n...   \n",
              "2  https://www.opednews.com/articles/Hunter-finds...   \n",
              "3  https://www.irishtimes.com/news/offbeat/a-case...   \n",
              "4  https://www.theguardian.com/lifeandstyle/2020/...   \n",
              "\n",
              "                                        content.url2  \\\n",
              "0  https://www.austin360.com/entertainment/201912...   \n",
              "1  https://www.washingtonpost.com/world/the_ameri...   \n",
              "2  https://guardian.ng/features/health/leading-an...   \n",
              "3  https://www.amazon.com/Normal-People-Novel-Sal...   \n",
              "4  https://wreg.com/2020/01/01/how-to-succeed-at-...   \n",
              "\n",
              "                                      content.title1  \\\n",
              "0  New brewery  in Sleepy Eye draws a crowd , Spo...   \n",
              "1          Winning numbers drawn in ‚ÄòCash4Life‚Äô game   \n",
              "2  Article- Hunter finds Schuylkill- The \"Hidden ...   \n",
              "3  A case of criminal lunacy- The sad killing of ...   \n",
              "4        The joy audit- how to have more fun in 2020   \n",
              "\n",
              "                                      content.title2 real_lang1 real_lang2  \\\n",
              "0  New North Austin brewery, Hopsquad, opens befo...         en         en   \n",
              "1  Haiti‚Äôs leader marks independence day amid sec...         en         en   \n",
              "2         Leading and managing organisational change         en         en   \n",
              "3  Normal People: A Novel: Sally Rooney: 97819848...         en         en   \n",
              "4  How to succeed at your New Years resolutions t...         en         en   \n",
              "\n",
              "               GEO  ... GEO_num ENT_num TIME_num NAR_num STYLE_num TONE_num  \\\n",
              "0  Very Dissimilar  ...     1.0     2.0      4.0     4.0       4.0      4.0   \n",
              "1  Very Dissimilar  ...     1.0     1.0      4.0     1.0       4.0      1.0   \n",
              "2  Very Dissimilar  ...     1.0     1.0      4.0     1.0       1.0      1.0   \n",
              "3     Very Similar  ...     4.0     1.0      1.0     1.0       1.0      1.0   \n",
              "4     Very Similar  ...     4.0     2.0      4.0     3.0       4.0      4.0   \n",
              "\n",
              "  FRAME_num OVERALL_num  url1_exists  url2_exists  \n",
              "0       NaN         2.0         True         True  \n",
              "1       NaN         1.0        False        False  \n",
              "2       NaN         1.0         True         True  \n",
              "3       NaN         1.0         True        False  \n",
              "4       NaN         1.0         True        False  \n",
              "\n",
              "[5 rows x 29 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b0b563b2-c00f-4057-b1e9-f5d502cdc071\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>content.pair_id</th>\n",
              "      <th>content.similarity</th>\n",
              "      <th>content.url1</th>\n",
              "      <th>content.url2</th>\n",
              "      <th>content.title1</th>\n",
              "      <th>content.title2</th>\n",
              "      <th>real_lang1</th>\n",
              "      <th>real_lang2</th>\n",
              "      <th>GEO</th>\n",
              "      <th>...</th>\n",
              "      <th>GEO_num</th>\n",
              "      <th>ENT_num</th>\n",
              "      <th>TIME_num</th>\n",
              "      <th>NAR_num</th>\n",
              "      <th>STYLE_num</th>\n",
              "      <th>TONE_num</th>\n",
              "      <th>FRAME_num</th>\n",
              "      <th>OVERALL_num</th>\n",
              "      <th>url1_exists</th>\n",
              "      <th>url2_exists</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1484188922_1484188392</td>\n",
              "      <td>0.141053</td>\n",
              "      <td>https://www.marshallindependent.com/news/local...</td>\n",
              "      <td>https://www.austin360.com/entertainment/201912...</td>\n",
              "      <td>New brewery  in Sleepy Eye draws a crowd , Spo...</td>\n",
              "      <td>New North Austin brewery, Hopsquad, opens befo...</td>\n",
              "      <td>en</td>\n",
              "      <td>en</td>\n",
              "      <td>Very Dissimilar</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1484299489_1484110209</td>\n",
              "      <td>0.243056</td>\n",
              "      <td>https://www.washingtonpost.com/local/winning-n...</td>\n",
              "      <td>https://www.washingtonpost.com/world/the_ameri...</td>\n",
              "      <td>Winning numbers drawn in ‚ÄòCash4Life‚Äô game</td>\n",
              "      <td>Haiti‚Äôs leader marks independence day amid sec...</td>\n",
              "      <td>en</td>\n",
              "      <td>en</td>\n",
              "      <td>Very Dissimilar</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1484188635_1484299664</td>\n",
              "      <td>0.097911</td>\n",
              "      <td>https://www.opednews.com/articles/Hunter-finds...</td>\n",
              "      <td>https://guardian.ng/features/health/leading-an...</td>\n",
              "      <td>Article- Hunter finds Schuylkill- The \"Hidden ...</td>\n",
              "      <td>Leading and managing organisational change</td>\n",
              "      <td>en</td>\n",
              "      <td>en</td>\n",
              "      <td>Very Dissimilar</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1484188331_1484347237</td>\n",
              "      <td>0.129065</td>\n",
              "      <td>https://www.irishtimes.com/news/offbeat/a-case...</td>\n",
              "      <td>https://www.amazon.com/Normal-People-Novel-Sal...</td>\n",
              "      <td>A case of criminal lunacy- The sad killing of ...</td>\n",
              "      <td>Normal People: A Novel: Sally Rooney: 97819848...</td>\n",
              "      <td>en</td>\n",
              "      <td>en</td>\n",
              "      <td>Very Similar</td>\n",
              "      <td>...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1484010809_1484223087</td>\n",
              "      <td>0.188465</td>\n",
              "      <td>https://www.theguardian.com/lifeandstyle/2020/...</td>\n",
              "      <td>https://wreg.com/2020/01/01/how-to-succeed-at-...</td>\n",
              "      <td>The joy audit- how to have more fun in 2020</td>\n",
              "      <td>How to succeed at your New Years resolutions t...</td>\n",
              "      <td>en</td>\n",
              "      <td>en</td>\n",
              "      <td>Very Similar</td>\n",
              "      <td>...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 29 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b0b563b2-c00f-4057-b1e9-f5d502cdc071')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b0b563b2-c00f-4057-b1e9-f5d502cdc071 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b0b563b2-c00f-4057-b1e9-f5d502cdc071');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9c3d738d-7848-455f-a67d-b328bfc10b4a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9c3d738d-7848-455f-a67d-b328bfc10b4a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9c3d738d-7848-455f-a67d-b328bfc10b4a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### New URL Columns Appended"
      ],
      "metadata": {
        "id": "-Q1QyJPzmhJE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url_cols = [c for c in (\"content.url1\", \"content.url2\") if c in df.columns]\n",
        "\n",
        "# Sanity check: ensure both expected columns exist\n",
        "assert len(url_cols) == 2, (\n",
        "    f\"Expected columns content.url1 & content.url2, but found: {url_cols}\"\n",
        ")\n",
        "print(f\"‚úÖ Found URL columns: {url_cols}\")"
      ],
      "metadata": {
        "id": "4may5-XvmWNJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cceeb5ab-edde-4640-fa95-21ed17ebcaf1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Found URL columns: ['content.url1', 'content.url2']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Extraction, Embedding and Comparison Using Siamese Model\n",
        " - Extraction of text using helper functions\n",
        " - Embedded text from each set of urls\n",
        " - Calculated cosine similarity using the embeddings\n",
        " - Results Storage and Display\n"
      ],
      "metadata": {
        "id": "ewZrFKAcmqV_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "#  STEP 2: Extract, Embed, and Compare using Siamese Model\n",
        "# ================================================================\n",
        "rows = []\n",
        "\n",
        "for i, row in tqdm(df.iterrows(), total=len(df), desc=\"Crawling + Encoding\"):\n",
        "    u1, u2 = row[url_cols[0]], row[url_cols[1]]\n",
        "\n",
        "    # --- Fetch first 2 paragraphs from both URLs ---\n",
        "    p1a, p1b, s1 = fetch_first_two_paragraphs(u1) if is_valid_url(u1) else (None, None, \"invalid_url\")\n",
        "    p2a, p2b, s2 = fetch_first_two_paragraphs(u2) if is_valid_url(u2) else (None, None, \"invalid_url\")\n",
        "\n",
        "    # --- Combine first + second paragraphs ---\n",
        "    t1 = \" \".join([x for x in (p1a, p1b) if x])\n",
        "    t2 = \" \".join([x for x in (p2a, p2b) if x])\n",
        "\n",
        "    # --- Compute embeddings + cosine similarity ---\n",
        "    v1 = embed(t1)\n",
        "    v2 = embed(t2)\n",
        "    cos = cosine_sim(v1, v2)\n",
        "\n",
        "    rows.append({\n",
        "        \"content.url1\": u1,\n",
        "        \"content.url2\": u2,\n",
        "        \"url1.p1\": p1a, \"url1.p2\": p1b, \"url1.status\": s1,\n",
        "        \"url2.p1\": p2a, \"url2.p2\": p2b, \"url2.status\": s2,\n",
        "        \"siamese.text1\": t1 or None,\n",
        "        \"siamese.text2\": t2 or None,\n",
        "        \"similarity.cosine\": cos,\n",
        "    })\n",
        "\n",
        "# --- Merge results into main dataframe ---\n",
        "result = pd.DataFrame(rows)\n",
        "siamese_output = df.join(result.drop(columns=[\"content.url1\", \"content.url2\"]).set_index(result.index))\n",
        "siamese_output.to_csv(\"siamese_output.csv\", index=False)\n",
        "\n",
        "# --- Preview results instead of saving ---\n",
        "print(\"‚úÖ Siamese comparison complete.\")\n",
        "display(siamese_output.head())\n",
        "print(f\"Total processed pairs: {len(siamese_output)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397,
          "referenced_widgets": [
            "6475e29c9be8488c984df09941f83bb2",
            "60fdf7e49d3d4681807d4ded88d7425f",
            "597db6322df145f2888149100338d766",
            "80bd4d39a43d4818aa3ccfb8b66fadb0",
            "3df19f1fa38c4bf79591b40b283e5008",
            "2372001d365b42c9acacb0c12f36def2",
            "d689d108212644ddabe6c607aa66afd6",
            "44f91466802d4b64bf8df8b3b0db0f16",
            "8134b48a8438486babd452826d9b1d76",
            "68808ec8c4a14d8e881c75f8b22596c6",
            "1238c2054ca34ae3802ca526c1411abf"
          ]
        },
        "id": "6Yhq_-dNjQ3H",
        "outputId": "aa6ef988-1ab0-4f2a-8f43-8312753d1ecb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Crawling + Encoding:   0%|          | 0/26555 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6475e29c9be8488c984df09941f83bb2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2047576209.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# --- Fetch first 2 paragraphs from both URLs ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mp1a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp1b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_first_two_paragraphs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_valid_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"invalid_url\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mp2a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp2b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_first_two_paragraphs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_valid_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"invalid_url\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-206361639.py\u001b[0m in \u001b[0;36mfetch_first_two_paragraphs\u001b[0;34m(url, timeout)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m# --- Attempt using Trafilatura ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mdownloaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrafilatura\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_ssl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdownloaded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrafilatura\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownloaded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_comments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_tables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/trafilatura/downloads.py\u001b[0m in \u001b[0;36mfetch_url\u001b[0;34m(url, no_ssl, config, options)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \"\"\"\n\u001b[1;32m    281\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moptions\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_ssl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mno_ssl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/trafilatura/downloads.py\u001b[0m in \u001b[0;36mfetch_response\u001b[0;34m(url, decode, no_ssl, with_headers, config)\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0mdl_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_send_urllib_request\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mHAS_PYCURL\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_send_pycurl_request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sending request: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdl_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_ssl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_headers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# None or \"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"request failed: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/trafilatura/downloads.py\u001b[0m in \u001b[0;36m_send_urllib_request\u001b[0;34m(url, no_ssl, with_headers, config)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;31m# execute request, stop downloading as soon as MAX_FILE_SIZE is reached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         response = pool_manager.request(\n\u001b[0m\u001b[1;32m    213\u001b[0m             \u001b[0;34m\"GET\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/_request_methods.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, fields, headers, json, **urlopen_kw)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encode_url_methods\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             return self.request_encode_url(\n\u001b[0m\u001b[1;32m    136\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/_request_methods.py\u001b[0m in \u001b[0;36mrequest_encode_url\u001b[0;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0murl\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"?\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0murlencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     def request_encode_body(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/poolmanager.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0mredirect_location\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mredirect\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_redirect_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    788\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;31m# Receive the response from the server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1428\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1431\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1249\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1251\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1101\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Final Result Siamese"
      ],
      "metadata": {
        "id": "h6OsplJesr5B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "siamese_output.head()"
      ],
      "metadata": {
        "id": "CcpPykIIskws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PsRLCOHJnV2k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dependencies and Imports (5W1H)"
      ],
      "metadata": {
        "id": "6T4IosABoJj4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "import time\n",
        "import requests\n",
        "import zipfile\n",
        "from datetime import datetime, timezone\n",
        "from Giveme5W1H.extractor.extractor import MasterExtractor\n",
        "from Giveme5W1H.extractor.document import Document\n",
        "from Giveme5W1H.extractor.extractors.environment_extractor import EnvironmentExtractor\n",
        "from Giveme5W1H.extractor.preprocessors.preprocessor_core_nlp import Preprocessor\n",
        "from geopy.geocoders import options\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "wIdb3EE1jUu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Giveme5W1H extractor and CoreNLP preprocessor setup"
      ],
      "metadata": {
        "id": "mu5kepsQo_rF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Install Dependencies and initialize stanza"
      ],
      "metadata": {
        "id": "uVkMIMH71toZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Java and stanza\n",
        "!apt-get update -q\n",
        "!apt-get install -y openjdk-17-jdk unzip wget -q\n",
        "!pip install stanza requests -q\n",
        "\n",
        "# Download and install CoreNLP via stanza helper\n",
        "import stanza\n",
        "stanza.install_corenlp()   # This will download stanford-corenlp-4.5.5 to ~/.stanfordnlp_resources/\n"
      ],
      "metadata": {
        "id": "z0gLlbRGxaiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from stanza.server import CoreNLPClient\n",
        "\n",
        "# with CoreNLPClient(\n",
        "#     annotators=['tokenize','ssplit','pos','lemma','ner','parse','depparse'],\n",
        "#     timeout=60000,\n",
        "#     memory='2G',\n",
        "#     be_quiet=False\n",
        "# ) as client:\n",
        "#     ann = client.annotate(\"Barack Obama was born in Hawaii.\")\n",
        "#     print(ann)"
      ],
      "metadata": {
        "id": "dzyogJYvxQB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Connect to preprocessor server and configure Giveme5W1H extractor"
      ],
      "metadata": {
        "id": "FnwnX1Za13LR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def download_and_setup_corenlp():\n",
        "    \"\"\"Download and extract Stanford CoreNLP.\"\"\"\n",
        "    base_path = os.path.expanduser(\"~/.stanfordnlp_resources\")\n",
        "    corenlp_version = \"4.5.7\"\n",
        "    corenlp_dir = f\"{base_path}/stanford-corenlp-{corenlp_version}\"\n",
        "    os.makedirs(base_path, exist_ok=True)\n",
        "\n",
        "    if os.path.exists(corenlp_dir):\n",
        "        print(f\"‚úì CoreNLP already exists at {corenlp_dir}\")\n",
        "        return corenlp_dir\n",
        "\n",
        "    # Download CoreNLP\n",
        "    url = f\"https://nlp.stanford.edu/software/stanford-corenlp-{corenlp_version}.zip\"\n",
        "    zip_path = f\"{base_path}/stanford-corenlp-{corenlp_version}.zip\"\n",
        "    print(f\"‚¨áÔ∏è  Downloading CoreNLP {corenlp_version} (~500 MB)...\")\n",
        "\n",
        "    result = subprocess.run([\"wget\", \"-q\", \"--show-progress\", url, \"-O\", zip_path])\n",
        "    if result.returncode != 0:\n",
        "        raise RuntimeError(f\"Failed to download CoreNLP from {url}\")\n",
        "\n",
        "    print(\"üì¶ Extracting CoreNLP...\")\n",
        "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "        zip_ref.extractall(base_path)\n",
        "    os.remove(zip_path)\n",
        "\n",
        "    print(f\"‚úì CoreNLP installed at {corenlp_dir}\")\n",
        "    return corenlp_dir\n",
        "\n",
        "\n",
        "def start_corenlp_server(corenlp_home, port=9020):\n",
        "    \"\"\"Start CoreNLP server in background.\"\"\"\n",
        "    try:\n",
        "        requests.get(f\"http://127.0.0.1:{port}\", timeout=2)\n",
        "        print(f\"‚úì CoreNLP server already running on port {port}\")\n",
        "        return\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    print(f\"üöÄ Starting CoreNLP server on port {port}...\")\n",
        "    cmd = [\n",
        "          \"java\", \"-Xmx4g\",\n",
        "          \"-cp\", f\"{corenlp_home}/*\",\n",
        "          \"edu.stanford.nlp.pipeline.StanfordCoreNLPServer\",\n",
        "          \"--port\", str(port),\n",
        "          \"--timeout\", \"500000\",\n",
        "          \"--annotators\", \"tokenize,ssplit,pos,lemma,ner,parse,depparse,coref\",\n",
        "          \"--preload\", \"tokenize,ssplit,pos,lemma,ner,parse,depparse,coref\",\n",
        "          \"--coref.algorithm\", \"neural\"\n",
        "      ]\n",
        "    process = subprocess.Popen(cmd, cwd=corenlp_home,\n",
        "                               stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "\n",
        "    print(\"‚è≥ Waiting for server to start\", end=\"\")\n",
        "    for i in range(90):\n",
        "        try:\n",
        "            requests.get(f\"http://127.0.0.1:{port}\", timeout=2)\n",
        "            print(f\"\\n‚úì CoreNLP server started successfully (took {i+1}s)\")\n",
        "            return\n",
        "        except Exception:\n",
        "            print(\".\", end=\"\", flush=True)\n",
        "            time.sleep(1)\n",
        "    raise RuntimeError(\"‚ùå Failed to start CoreNLP server after 90 s\")\n",
        "\n"
      ],
      "metadata": {
        "id": "ptCPUbiB3Gb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initialize Giveme5W1H extractor and CoreNLP preprocessor\n",
        "corenlp_home = download_and_setup_corenlp()\n",
        "# start_corenlp_server(corenlp_home, port=9020) only if not manually ran\n",
        "options.default_user_agent = \"colab-giveme5w1h\"\n",
        "try:\n",
        "  pre = Preprocessor(\"http://127.0.0.1:9020\")  # assumes CoreNLP server is running\n",
        "  pre._Preprocessor__default_annotators = \"tokenize,ssplit,pos,lemma,ner,parse,depparse,coref\"\n",
        "\n",
        "  print(\"‚úÖ CoreNLP server is running!\")\n",
        "except Exception as e:\n",
        "    print(\"‚ùå CoreNLP server not reachable:\", e)\n",
        "\n",
        "extractor = MasterExtractor(preprocessor=pre)\n",
        "\n",
        "# remove environment extractor for speed\n",
        "extractor.extractors = [e for e in extractor.extractors if not isinstance(e, EnvironmentExtractor)]\n",
        "\n",
        "TITLE_COLS = [c for c in (\"content.title1\", \"content.title2\") if c in df.columns]"
      ],
      "metadata": {
        "id": "UWQkhnmz5y3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helper function to extract 5w1h from title and process it"
      ],
      "metadata": {
        "id": "YtOMwQzxpOlf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Sanitize Title\n"
      ],
      "metadata": {
        "id": "5R8Djr-0Gr_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import html, re, json\n",
        "\n",
        "def sanitize_title(title: str) -> str:\n",
        "    \"\"\"Clean up titles for better NLP parsing.\"\"\"\n",
        "    title = re.sub(r'\\s+', ' ', title)\n",
        "    title = re.sub(r'[^\\w\\s,\\'\"-]', '', title)\n",
        "    return title.strip()"
      ],
      "metadata": {
        "id": "4Olx_6i2GvTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ner_fallback(text: str):\n",
        "    \"\"\"Fallback extractor using CoreNLP NER for short texts.\"\"\"\n",
        "    props = {\"annotators\": \"tokenize,ssplit,pos,lemma,ner\", \"outputFormat\": \"json\"}\n",
        "    try:\n",
        "        r = requests.post(\n",
        "            \"http://127.0.0.1:9020\",\n",
        "            params={\"properties\": json.dumps(props)},\n",
        "            data=text.encode(\"utf-8\"),\n",
        "            headers={\"Content-Type\": \"text/plain; charset=utf-8\"},\n",
        "            timeout=15\n",
        "        )\n",
        "        data = r.json()\n",
        "        entities = [(ent[\"text\"], ent[\"ner\"])\n",
        "                    for sent in data.get(\"sentences\", [])\n",
        "                    for ent in sent.get(\"entitymentions\", [])]\n",
        "\n",
        "        who = \" \".join([t for t, n in entities if n in {\"PERSON\", \"ORGANIZATION\"}]) or None\n",
        "        where = \" \".join([t for t, n in entities if n in {\"LOCATION\", \"CITY\", \"STATE_OR_PROVINCE\", \"COUNTRY\"}]) or None\n",
        "        when = \" \".join([t for t, n in entities if n in {\"DATE\", \"TIME\"}]) or None\n",
        "\n",
        "        what = re.sub(r\"[^\\w\\s,'-]\", \"\", text).strip() or None\n",
        "        return {\"who\": who, \"what\": what, \"when\": when, \"where\": where, \"why\": None, \"how\": None}\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå NER fallback failed: {e}\")\n",
        "        return {k: None for k in [\"who\", \"what\", \"when\", \"where\", \"why\", \"how\"]}\n",
        "\n",
        "\n",
        "def extract_5w1h_from_title(title: str):\n",
        "    \"\"\"Main extractor with GiveMe5W1H + fallback.\"\"\"\n",
        "    if not isinstance(title, str) or not title.strip():\n",
        "        return {k: None for k in [\"who\", \"what\", \"when\", \"where\", \"why\", \"how\"]}\n",
        "    try:\n",
        "        doc = Document.from_text(title)\n",
        "        doc = extractor.parse(doc)\n",
        "        def safe_extract(q):\n",
        "            try:\n",
        "                return doc.get_top_answer(q).get_parts_as_text()\n",
        "            except Exception:\n",
        "                return None\n",
        "        result = {q: safe_extract(q) for q in [\"who\", \"what\", \"when\", \"where\", \"why\", \"how\"]}\n",
        "        if all(v is None for v in result.values()):\n",
        "            result.update(ner_fallback(title))\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Fallback triggered for '{title[:60]}...': {e}\")\n",
        "        return ner_fallback(title)\n",
        "\n"
      ],
      "metadata": {
        "id": "xWTXwvI9jbOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(extract_5w1h_from_title(\"Porter‚Äôs factor conditions for countries‚Äô competitiveness are demand condition, related industries, firm‚Äôs strategy, and the level of rivalry. Australia has been challenged for the trophy and there was an increased demand for the country to produce results in the game. The country through several failures to lift the trophy had learned its weaknesses, and in 2005, it went to the games with polished strategies to face their rivals. This led to its victory.\"))"
      ],
      "metadata": {
        "id": "7KnvkCiqt9nA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Text Extraction"
      ],
      "metadata": {
        "id": "iDa5L9HHprw_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 3: Apply Across Titles\n",
        "# ============================================================\n",
        "def process_titles_once(df, title_cols):\n",
        "    \"\"\"Apply 5W1H extraction to all given title columns with progress tracking.\"\"\"\n",
        "    result_df = df.copy()\n",
        "    for col in title_cols:\n",
        "        if col not in result_df.columns:\n",
        "            print(f\"‚ö†Ô∏è Skipping {col}: not found in dataframe\")\n",
        "            continue\n",
        "\n",
        "        print(f\"\\nüöÄ Processing {col} ({len(result_df)} titles)\")\n",
        "        results = []\n",
        "        for idx, title in enumerate(result_df[col].fillna(\"\")):\n",
        "            if idx % 10 == 0:\n",
        "                print(f\"  ‚Üí Progress: {idx}/{len(result_df)}\", end=\"\\r\")\n",
        "            if idx % 100 == 0 and idx > 0:\n",
        "                time.sleep(0.3)\n",
        "\n",
        "            clean_title = re.sub(r\"\\s+\", \" \", str(title)).strip()\n",
        "            if clean_title:\n",
        "                results.append(extract_5w1h_from_title(clean_title))\n",
        "            else:\n",
        "                results.append({k: None for k in [\"who\", \"what\", \"when\", \"where\", \"why\", \"how\"]})\n",
        "\n",
        "        col_results = pd.DataFrame.from_records(results, index=result_df.index)\n",
        "        for q in col_results.columns:\n",
        "            result_df[f\"{col}.{q}\"] = col_results[q].values\n",
        "        print(f\"‚úÖ Completed {col} ({len(result_df)} titles)\")\n",
        "\n",
        "    result_df = result_df.loc[:, ~result_df.columns.duplicated(keep=\"last\")]\n",
        "    return result_df\n"
      ],
      "metadata": {
        "id": "EfWFAlcLlYED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Starting 5W1H extraction...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "TITLE_COLS = [c for c in (\"content.title1\", \"content.title2\") if c in df.columns]\n",
        "result_df = process_titles_once(df, TITLE_COLS)\n",
        "\n",
        "preview_cols = [f\"{c}.{q}\" for c in TITLE_COLS for q in (\"who\",\"what\",\"when\",\"where\",\"why\",\"how\")]\n",
        "keep = [c for c in [\"content.url1\",\"content.url2\",\"content.title1\",\"content.title2\"] if c in result_df.columns] + [c for c in preview_cols if c in result_df.columns]\n",
        "result_df = result_df[keep]"
      ],
      "metadata": {
        "id": "7jQUm99cjc_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing the connection\n",
        "# import requests, json\n",
        "# text = sanitize_title(\"NASA launches Artemis mission to the Moon\")\n",
        "# props = {\n",
        "#     \"annotators\": \"tokenize,ssplit,pos,lemma,ner\",\n",
        "#     \"outputFormat\": \"json\"\n",
        "# }\n",
        "# r = requests.post(\n",
        "#     \"http://127.0.0.1:9010\",\n",
        "#     params={\"properties\": json.dumps(props)},\n",
        "#     data=text.encode(\"utf-8\"),\n",
        "#     headers={\"Content-Type\": \"text/plain; charset=utf-8\"}\n",
        "# )\n",
        "# print(r.status_code)\n",
        "# print(r.text[:300])\n"
      ],
      "metadata": {
        "id": "i7mJh1nmIExa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Save and Display results"
      ],
      "metadata": {
        "id": "DbKBSKZ9pukc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(result_df.head())\n",
        "fivew1h_output = result_df\n",
        "fivew1h_output.to_csv(\"fivew1h_output.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "SGzgG3jepmxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Entity Based Similarity & Fusion with Siamese Network"
      ],
      "metadata": {
        "id": "tVlFvF0C6H97"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.spatial.distance import euclidean\n",
        "from scipy.stats import pearsonr"
      ],
      "metadata": {
        "id": "XkKgUUFp6UKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the previous 5W1H output directly (not from CSV)\n",
        "# fivew1h_output already has content.title1.*, content.title2.* columns\n",
        "fusion_df = fivew1h_output.copy()"
      ],
      "metadata": {
        "id": "0MKFL-7E6XK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- Helper functions ---\n",
        "def calculate_entity_overlap(entity1, entity2):\n",
        "    \"\"\"Calculate overlap between two entities (Jaccard similarity).\"\"\"\n",
        "    if not entity1 or not entity2:\n",
        "        return 0.0\n",
        "\n",
        "    set1 = set(str(entity1).lower().split())\n",
        "    set2 = set(str(entity2).lower().split())\n",
        "\n",
        "    if len(set1) == 0 and len(set2) == 0:\n",
        "        return 1.0\n",
        "    if len(set1) == 0 or len(set2) == 0:\n",
        "        return 0.0\n",
        "\n",
        "    intersection = len(set1.intersection(set2))\n",
        "    union = len(set1.union(set2))\n",
        "    return intersection / union if union > 0 else 0.0\n",
        "\n",
        "def calculate_5w1h_similarity(row):\n",
        "    \"\"\"Calculate entity-based similarity for a pair of articles.\"\"\"\n",
        "    questions = ['who', 'what', 'when', 'where', 'why', 'how']\n",
        "    similarities = {}\n",
        "\n",
        "    for q in questions:\n",
        "        col1 = f'content.title1.{q}'\n",
        "        col2 = f'content.title2.{q}'\n",
        "\n",
        "        if col1 in row.index and col2 in row.index:\n",
        "            entity1 = row[col1]\n",
        "            entity2 = row[col2]\n",
        "            similarities[q] = calculate_entity_overlap(entity1, entity2)\n",
        "        else:\n",
        "            similarities[q] = 0.0\n",
        "\n",
        "    avg_entity_sim = np.mean(list(similarities.values()))\n",
        "    return pd.Series({\n",
        "        'entity_who_sim': similarities['who'],\n",
        "        'entity_what_sim': similarities['what'],\n",
        "        'entity_when_sim': similarities['when'],\n",
        "        'entity_where_sim': similarities['where'],\n",
        "        'entity_why_sim': similarities['why'],\n",
        "        'entity_how_sim': similarities['how'],\n",
        "        'avg_entity_similarity': avg_entity_sim\n",
        "    })\n",
        "\n",
        "# --- Apply entity similarity computation ---\n",
        "entity_similarities = fusion_df.apply(calculate_5w1h_similarity, axis=1)\n",
        "fusion_df = pd.concat([fusion_df, entity_similarities], axis=1)\n",
        "\n",
        "print(\"‚úì Entity-based similarities calculated successfully.\")\n",
        "\n",
        "# Handle duplicated or non-standard column safely\n",
        "if 'avg_entity_similarity' in fusion_df.columns:\n",
        "    # If there are duplicate columns, keep only the last one\n",
        "    if isinstance(fusion_df['avg_entity_similarity'], pd.DataFrame):\n",
        "        avg_sim_col = fusion_df['avg_entity_similarity'].iloc[:, -1]\n",
        "    else:\n",
        "        avg_sim_col = fusion_df['avg_entity_similarity']\n",
        "\n",
        "    # Ensure Series is flat numeric\n",
        "    avg_sim_flat = pd.to_numeric(avg_sim_col.astype(str).str.extract(r'([\\d.]+)')[0], errors='coerce')\n",
        "    mean_val = float(avg_sim_flat.mean()) if not avg_sim_flat.isna().all() else 0.0\n",
        "    print(f\"  - Average entity similarity across dataset: {mean_val:.4f}\")\n",
        "else:\n",
        "    print(\"  - Warning: avg_entity_similarity column not found.\")\n",
        "# --- Preview output ---\n",
        "preview_cols = [\n",
        "    \"content.url1\", \"content.url2\",\n",
        "    \"content.title1\", \"content.title2\",\n",
        "    \"avg_entity_similarity\", \"entity_who_sim\", \"entity_what_sim\", \"entity_when_sim\",\n",
        "    \"entity_where_sim\", \"entity_why_sim\", \"entity_how_sim\"\n",
        "]\n",
        "print(\"\\nSample output:\")\n",
        "display(fusion_df[preview_cols].head())\n",
        "\n",
        "# For later fusion with Siamese results\n",
        "entity_output = fusion_df\n"
      ],
      "metadata": {
        "id": "FpFd1Ap66c_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### STEP 5: Fusion Layer (Entity + Embedding Similarity)"
      ],
      "metadata": {
        "id": "iHnjaAvz6uKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "#  STEP 5: Fusion Layer ‚Äî Combine Entity and Siamese Similarities\n",
        "# ================================================================\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 5: Fusion Layer (Entity + Siamese Network)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# --- Merge Siamese and Entity-based results ---\n",
        "fusion_df = pd.merge(\n",
        "    siamese_output,\n",
        "    entity_output[[\"content.url1\", \"content.url2\", \"avg_entity_similarity\"]],\n",
        "    on=[\"content.url1\", \"content.url2\"],\n",
        "    how=\"left\"\n",
        ")\n",
        "\n",
        "# --- Rename for clarity ---\n",
        "fusion_df = fusion_df.loc[:, ~fusion_df.columns.duplicated()]  # remove duplicates\n",
        "fusion_df.rename(columns={\"similarity.cosine\": \"siamese_similarity\"}, inplace=True)\n",
        "\n",
        "# --- Ensure numeric columns ---\n",
        "fusion_df[\"avg_entity_similarity\"] = pd.to_numeric(\n",
        "    fusion_df[\"avg_entity_similarity\"], errors=\"coerce\"\n",
        ").fillna(0)\n",
        "fusion_df[\"siamese_similarity\"] = pd.to_numeric(\n",
        "    fusion_df[\"siamese_similarity\"], errors=\"coerce\"\n",
        ").fillna(0)\n",
        "\n",
        "# --- Define fusion function ---\n",
        "def fusion_similarity(entity_sim, siamese_sim, entity_weight=0.4, siamese_weight=0.6):\n",
        "    \"\"\"Combine entity-based and embedding-based (Siamese) similarities.\"\"\"\n",
        "    return (entity_weight * entity_sim) + (siamese_weight * siamese_sim)\n",
        "\n",
        "# --- Compute fusion vectorized (faster & safer than .apply) ---\n",
        "fusion_df[\"fused_similarity\"] = fusion_similarity(\n",
        "    fusion_df[\"avg_entity_similarity\"],\n",
        "    fusion_df[\"siamese_similarity\"],\n",
        "    entity_weight=0.4,\n",
        "    siamese_weight=0.6,\n",
        ")\n",
        "\n",
        "# --- Summary statistics ---\n",
        "mean_val = fusion_df[\"fused_similarity\"].mean()\n",
        "print(\"‚úì Fusion similarity calculated successfully.\")\n",
        "print(f\"  - Average fused similarity: {mean_val:.4f}\")\n",
        "print(f\"  - Min fused similarity: {fusion_df['fused_similarity'].min():.4f}\")\n",
        "print(f\"  - Max fused similarity: {fusion_df['fused_similarity'].max():.4f}\")\n",
        "\n",
        "# --- Preview ---\n",
        "display(\n",
        "    fusion_df[\n",
        "        [\n",
        "            \"content.url1\",\n",
        "            \"content.url2\",\n",
        "            \"siamese_similarity\",\n",
        "            \"avg_entity_similarity\",\n",
        "            \"fused_similarity\",\n",
        "        ]\n",
        "    ].head()\n",
        ")\n",
        "\n",
        "# For final saving\n",
        "final_output = fusion_df\n"
      ],
      "metadata": {
        "id": "OYjx0Utp6tFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####  STEP 7: Pearson Correlation Analysis\n"
      ],
      "metadata": {
        "id": "Oe2TlxZD64aV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "#  STEP 7: Pearson Correlation Analysis\n",
        "# ================================================================\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 7: Pearson Correlation Analysis\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Use the latest unified dataframe from Step 5\n",
        "correlation_df = final_output.copy()\n",
        "\n",
        "# Identify available columns\n",
        "correlation_cols = [\n",
        "    \"entity_who_sim\", \"entity_what_sim\", \"entity_when_sim\",\n",
        "    \"entity_where_sim\", \"entity_why_sim\", \"entity_how_sim\",\n",
        "    \"avg_entity_similarity\", \"siamese_similarity\", \"fused_similarity\",\n",
        "]\n",
        "correlation_cols = [col for col in correlation_cols if col in correlation_df.columns]\n",
        "\n",
        "# --- Compute correlation matrix ---\n",
        "if correlation_cols:\n",
        "    correlation_matrix = correlation_df[correlation_cols].corr(method=\"pearson\")\n",
        "    print(\"\\nPearson Correlation Matrix:\")\n",
        "    print(correlation_matrix.round(3))\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No valid similarity columns found for correlation analysis.\")\n",
        "\n",
        "# --- Key correlations ---\n",
        "print(\"\\n\" + \"-\" * 60)\n",
        "print(\"Key Correlations:\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "def safe_corr(x, y):\n",
        "    \"\"\"Compute Pearson correlation safely.\"\"\"\n",
        "    try:\n",
        "        corr, p_val = pearsonr(\n",
        "            correlation_df[x].fillna(0).astype(float),\n",
        "            correlation_df[y].fillna(0).astype(float),\n",
        "        )\n",
        "        return corr, p_val\n",
        "    except Exception:\n",
        "        return np.nan, np.nan\n",
        "\n",
        "if \"avg_entity_similarity\" in correlation_df.columns and \"siamese_similarity\" in correlation_df.columns:\n",
        "    corr, p_val = safe_corr(\"avg_entity_similarity\", \"siamese_similarity\")\n",
        "    print(f\"Entity vs Siamese Similarity: r={corr:.4f}, p={p_val:.4e}\")\n",
        "\n",
        "if \"fused_similarity\" in correlation_df.columns and \"siamese_similarity\" in correlation_df.columns:\n",
        "    corr, p_val = safe_corr(\"fused_similarity\", \"siamese_similarity\")\n",
        "    print(f\"Fused vs Siamese Similarity: r={corr:.4f}, p={p_val:.4e}\")\n",
        "\n",
        "if \"fused_similarity\" in correlation_df.columns and \"avg_entity_similarity\" in correlation_df.columns:\n",
        "    corr, p_val = safe_corr(\"fused_similarity\", \"avg_entity_similarity\")\n",
        "    print(f\"Fused vs Entity Similarity: r={corr:.4f}, p={p_val:.4e}\")\n"
      ],
      "metadata": {
        "id": "tWSfv3ys639R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####  STEP 8: Save Results\n"
      ],
      "metadata": {
        "id": "-zqIQ--w7B1W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_df = final_output.copy()"
      ],
      "metadata": {
        "id": "nI3i6dKnQ-Lj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 8: Saving Results\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "final_columns = [\n",
        "    'content.url1', 'content.url2',\n",
        "    'content.title1', 'content.title2',\n",
        "    'content.title1.who', 'content.title1.what', 'content.title1.when',\n",
        "    'content.title1.where', 'content.title1.why', 'content.title1.how',\n",
        "    'content.title2.who', 'content.title2.what', 'content.title2.when',\n",
        "    'content.title2.where', 'content.title2.why', 'content.title2.how',\n",
        "    'entity_who_sim', 'entity_what_sim', 'entity_when_sim',\n",
        "    'entity_where_sim', 'entity_why_sim', 'entity_how_sim',\n",
        "    'avg_entity_similarity', 'siamese_similarity', 'fused_similarity'\n",
        "]\n",
        "\n",
        "final_columns = [c for c in final_columns if c in final_df.columns]\n",
        "\n",
        "# --- save results ---\n",
        "output_file = \"final_similarity_results.csv\"\n",
        "final_df[final_columns].to_csv(output_file, index=False)\n",
        "print(f\"‚úì Saved complete results to: {output_file}\")\n",
        "\n",
        "# --- save correlation matrix ---\n",
        "correlation_output = \"correlation_matrix.csv\"\n",
        "correlation_matrix.to_csv(correlation_output)\n",
        "print(f\"‚úì Saved correlation matrix to: {correlation_output}\")\n",
        "\n",
        "# --- save summary statistics (only existing numeric cols) ---\n",
        "summary_cols = [c for c in [\"avg_entity_similarity\", \"siamese_similarity\", \"fused_similarity\"]\n",
        "                if c in final_df.columns]\n",
        "if summary_cols:\n",
        "    summary_stats = final_df[summary_cols].describe()\n",
        "    summary_output = \"similarity_statistics.csv\"\n",
        "    summary_stats.to_csv(summary_output)\n",
        "    print(f\"‚úì Saved summary statistics to: {summary_output}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No similarity columns found for summary statistics.\")\n"
      ],
      "metadata": {
        "id": "Xo4oSunc7EiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####  STEP 9: Visualization and Analysis\n"
      ],
      "metadata": {
        "id": "xcPa6xJl7L1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 9: Summary Statistics & Analysis\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Display summary statistics\n",
        "print(\"\\nSimilarity Score Distribution:\")\n",
        "print(final_df[correlation_cols].describe().round(4))\n",
        "\n",
        "# Find top similar pairs\n",
        "print(\"\\n\" + \"-\"*60)\n",
        "print(\"Top 10 Most Similar Article Pairs (by Fused Similarity):\")\n",
        "print(\"-\"*60)\n",
        "top_similar = final_df.nlargest(10, 'fused_similarity')[\n",
        "    ['content.title1', 'content.title2', 'avg_entity_similarity',\n",
        "     'siamese_similarity', 'fused_similarity']\n",
        "]\n",
        "print(top_similar.to_string(index=False))\n",
        "\n",
        "# Find least similar pairs\n",
        "print(\"\\n\" + \"-\"*60)\n",
        "print(\"Top 10 Least Similar Article Pairs (by Fused Similarity):\")\n",
        "print(\"-\"*60)\n",
        "least_similar = final_df.nsmallest(10, 'fused_similarity')[\n",
        "    ['content.title1', 'content.title2', 'avg_entity_similarity',\n",
        "     'siamese_similarity', 'fused_similarity']\n",
        "]\n",
        "print(least_similar.to_string(index=False))\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úì Analysis Complete!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nGenerated files:\")\n",
        "print(f\"  1. {output_file}\")\n",
        "print(f\"  2. {correlation_output}\")\n",
        "print(f\"  3. {summary_output}\")"
      ],
      "metadata": {
        "id": "lcQf1fX-7J4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####  STEP 10: Quantitative Evaluation Metrics\n"
      ],
      "metadata": {
        "id": "gyNxqcdQ7q-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report,\n",
        "    precision_recall_curve, roc_curve, auc,\n",
        "    f1_score, precision_score, recall_score, accuracy_score\n",
        ")\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 10: Quantitative Evaluation Metrics\")\n",
        "print(\"=\"*60)\n"
      ],
      "metadata": {
        "id": "r-MQBF5C7nFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "#  Convert Continuous Scores to Binary Predictions\n",
        "# ================================================================\n",
        "\n",
        "def evaluate_at_threshold(y_true, y_scores, threshold):\n",
        "    \"\"\"Evaluate predictions at a specific threshold.\"\"\"\n",
        "    y_pred = (y_scores >= threshold).astype(int)\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
        "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
        "\n",
        "    return {\n",
        "        'threshold': threshold,\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1\n",
        "    }"
      ],
      "metadata": {
        "id": "mvQRLM9E8bYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "#  STEP 10: Use Real Ground Truth Labels\n",
        "# ================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 10: Using Real Ground Truth Labels (content.similarity)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "if \"content.similarity\" in final_df.columns:\n",
        "    # Use 0.5 as threshold to convert similarity into binary labels\n",
        "    final_df[\"ground_truth\"] = (final_df[\"content.similarity\"] >= 0.5).astype(int)\n",
        "    print(\"‚úÖ Ground truth labels loaded from 'content.similarity'.\")\n",
        "else:\n",
        "    raise ValueError(\"‚ùå 'content.similarity' column not found in dataset.\")\n",
        "\n",
        "print(f\"Total labelled pairs: {len(final_df)}\")\n",
        "print(final_df[[\"content.similarity\", \"fused_similarity\", \"ground_truth\"]].head())\n"
      ],
      "metadata": {
        "id": "X-Nf8lVx8nNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Test multiple thresholds\n",
        "thresholds_to_test = np.arange(0.1, 1.0, 0.05)\n",
        "y_true = final_df['ground_truth'].values\n",
        "\n",
        "# Evaluate each similarity measure\n",
        "similarity_measures = {\n",
        "    'Entity Similarity': 'avg_entity_similarity',\n",
        "    'Siamese Similarity': 'siamese_similarity',\n",
        "    'Fused Similarity': 'fused_similarity'\n",
        "}\n",
        "\n",
        "results_by_measure = {}\n",
        "\n",
        "for measure_name, measure_col in similarity_measures.items():\n",
        "    if measure_col in final_df.columns:\n",
        "        y_scores = final_df[measure_col].fillna(0).values\n",
        "\n",
        "        # Evaluate at different thresholds\n",
        "        threshold_results = []\n",
        "        for thresh in thresholds_to_test:\n",
        "            metrics = evaluate_at_threshold(y_true, y_scores, thresh)\n",
        "            threshold_results.append(metrics)\n",
        "\n",
        "        results_by_measure[measure_name] = {\n",
        "            'scores': y_scores,\n",
        "            'threshold_results': pd.DataFrame(threshold_results)\n",
        "        }"
      ],
      "metadata": {
        "id": "vW_yVavf8fCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"-\"*60)\n",
        "print(\"Optimal Thresholds (Maximum F1 Score):\")\n",
        "print(\"-\"*60)\n",
        "\n",
        "optimal_thresholds = {}\n",
        "\n",
        "for measure_name, data in results_by_measure.items():\n",
        "    df_thresh = data['threshold_results']\n",
        "    optimal_idx = df_thresh['f1'].idxmax()\n",
        "    optimal_row = df_thresh.iloc[optimal_idx]\n",
        "    optimal_thresholds[measure_name] = optimal_row['threshold']\n",
        "\n",
        "    print(f\"\\n{measure_name}:\")\n",
        "    print(f\"  Optimal Threshold: {optimal_row['threshold']:.3f}\")\n",
        "    print(f\"  Accuracy:  {optimal_row['accuracy']:.4f}\")\n",
        "    print(f\"  Precision: {optimal_row['precision']:.4f}\")\n",
        "    print(f\"  Recall:    {optimal_row['recall']:.4f}\")\n",
        "    print(f\"  F1 Score:  {optimal_row['f1']:.4f}\")"
      ],
      "metadata": {
        "id": "IGV5FtlO8qns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "######   Confusion Matrix\n",
        "\n"
      ],
      "metadata": {
        "id": "a0C1cSeH7wOy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Generating Confusion Matrices...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "fig.suptitle('Confusion Matrices at Optimal Thresholds', fontsize=16, fontweight='bold')\n",
        "\n",
        "for idx, (measure_name, measure_col) in enumerate(similarity_measures.items()):\n",
        "    if measure_col in final_df.columns:\n",
        "        y_scores = final_df[measure_col].fillna(0).values\n",
        "        threshold = optimal_thresholds[measure_name]\n",
        "        y_pred = (y_scores >= threshold).astype(int)\n",
        "\n",
        "        # Compute confusion matrix\n",
        "        cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "        # Plot\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                   cbar=False, ax=axes[idx],\n",
        "                   xticklabels=['Not Similar', 'Similar'],\n",
        "                   yticklabels=['Not Similar', 'Similar'])\n",
        "        axes[idx].set_title(f'{measure_name}\\n(Threshold: {threshold:.3f})')\n",
        "        axes[idx].set_ylabel('True Label')\n",
        "        axes[idx].set_xlabel('Predicted Label')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('confusion_matrices.png', dpi=300, bbox_inches='tight')\n",
        "print(\"‚úì Saved: confusion_matrices.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TzeVP-Gc78xl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ================================================================\n",
        "#  Precision-Recall Curves\n",
        "# ================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Generating Precision-Recall Curves...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "for measure_name, data in results_by_measure.items():\n",
        "    y_scores = data['scores']\n",
        "    precision, recall, _ = precision_recall_curve(y_true, y_scores)\n",
        "    pr_auc = auc(recall, precision)\n",
        "\n",
        "    ax.plot(recall, precision, label=f'{measure_name} (AUC={pr_auc:.3f})', linewidth=2)\n",
        "\n",
        "ax.set_xlabel('Recall', fontsize=12)\n",
        "ax.set_ylabel('Precision', fontsize=12)\n",
        "ax.set_title('Precision-Recall Curves', fontsize=14, fontweight='bold')\n",
        "ax.legend(loc='best', fontsize=10)\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.set_xlim([0, 1])\n",
        "ax.set_ylim([0, 1])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('precision_recall_curves.png', dpi=300, bbox_inches='tight')\n",
        "print(\"‚úì Saved: precision_recall_curves.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YtIcwCeJ8w4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ================================================================\n",
        "#  ROC Curves\n",
        "# ================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Generating ROC Curves...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "for measure_name, data in results_by_measure.items():\n",
        "    y_scores = data['scores']\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    ax.plot(fpr, tpr, label=f'{measure_name} (AUC={roc_auc:.3f})', linewidth=2)\n",
        "\n",
        "# Plot diagonal line\n",
        "ax.plot([0, 1], [0, 1], 'k--', label='Random Classifier', linewidth=1)\n",
        "\n",
        "ax.set_xlabel('False Positive Rate', fontsize=12)\n",
        "ax.set_ylabel('True Positive Rate', fontsize=12)\n",
        "ax.set_title('ROC Curves', fontsize=14, fontweight='bold')\n",
        "ax.legend(loc='lower right', fontsize=10)\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.set_xlim([0, 1])\n",
        "ax.set_ylim([0, 1])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('roc_curves.png', dpi=300, bbox_inches='tight')\n",
        "print(\"‚úì Saved: roc_curves.png\")\n",
        "plt.show()\n",
        "\n",
        "# ============"
      ],
      "metadata": {
        "id": "rg5nFDOj82N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "#  F1 Score vs Threshold Curves\n",
        "# ================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Generating F1 Score vs Threshold Curves...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "for measure_name, data in results_by_measure.items():\n",
        "    df_thresh = data['threshold_results']\n",
        "    ax.plot(df_thresh['threshold'], df_thresh['f1'],\n",
        "           label=measure_name, linewidth=2, marker='o', markersize=3)\n",
        "\n",
        "ax.set_xlabel('Threshold', fontsize=12)\n",
        "ax.set_ylabel('F1 Score', fontsize=12)\n",
        "ax.set_title('F1 Score vs Threshold', fontsize=14, fontweight='bold')\n",
        "ax.legend(loc='best', fontsize=10)\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.set_xlim([0, 1])\n",
        "ax.set_ylim([0, 1])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('f1_vs_threshold.png', dpi=300, bbox_inches='tight')\n",
        "print(\"‚úì Saved: f1_vs_threshold.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uu_uAc1T87RE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "#  Precision, Recall, F1 vs Threshold (Combined)\n",
        "# ================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Generating Combined Metrics vs Threshold...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "fig.suptitle('Metrics vs Threshold for Different Similarity Measures',\n",
        "             fontsize=16, fontweight='bold')\n",
        "\n",
        "metric_names = ['precision', 'recall', 'f1']\n",
        "metric_labels = ['Precision', 'Recall', 'F1 Score']\n",
        "\n",
        "for idx, (metric, label) in enumerate(zip(metric_names, metric_labels)):\n",
        "    for measure_name, data in results_by_measure.items():\n",
        "        df_thresh = data['threshold_results']\n",
        "        axes[idx].plot(df_thresh['threshold'], df_thresh[metric],\n",
        "                      label=measure_name, linewidth=2, marker='o', markersize=3)\n",
        "\n",
        "    axes[idx].set_xlabel('Threshold', fontsize=12)\n",
        "    axes[idx].set_ylabel(label, fontsize=12)\n",
        "    axes[idx].set_title(f'{label} vs Threshold', fontsize=12, fontweight='bold')\n",
        "    axes[idx].legend(loc='best', fontsize=9)\n",
        "    axes[idx].grid(True, alpha=0.3)\n",
        "    axes[idx].set_xlim([0, 1])\n",
        "    axes[idx].set_ylim([0, 1])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('metrics_vs_threshold.png', dpi=300, bbox_inches='tight')\n",
        "print(\"‚úì Saved: metrics_vs_threshold.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "d9bH3EAX9GWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Classification Reports at Optimal Thresholds:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "df_eval = final_df if 'fused_similarity' in final_df.columns else result_df.copy()\n",
        "\n",
        "for measure_name, measure_col in similarity_measures.items():\n",
        "    if measure_col in df_eval.columns:\n",
        "        y_scores = df_eval[measure_col].fillna(0).values\n",
        "        threshold = optimal_thresholds[measure_name]\n",
        "        y_pred = (y_scores >= threshold).astype(int)\n",
        "\n",
        "        print(f\"\\n{measure_name} (Threshold: {threshold:.3f}):\")\n",
        "        print(\"-\" * 60)\n",
        "        print(classification_report(\n",
        "            y_true, y_pred,\n",
        "            labels=[0, 1],  # <- ensures consistent output\n",
        "            target_names=['Not Similar', 'Similar'],\n",
        "            digits=4,\n",
        "            zero_division=0\n",
        "        ))\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Skipping {measure_name}: column '{measure_col}' not found.\")\n"
      ],
      "metadata": {
        "id": "NeDdQFAA9MB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Comparative Performance Summary:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Pick correct dataframe dynamically\n",
        "df_eval = final_df if 'fused_similarity' in final_df.columns else result_df.copy()\n",
        "\n",
        "performance_data = []\n",
        "\n",
        "for measure_name, measure_col in similarity_measures.items():\n",
        "    if measure_col not in df_eval.columns:\n",
        "        print(f\"‚ö†Ô∏è Skipping '{measure_name}' ‚Äî missing column '{measure_col}'.\")\n",
        "        continue\n",
        "\n",
        "    y_scores = df_eval[measure_col].fillna(0).values\n",
        "    threshold = optimal_thresholds.get(measure_name, np.median(y_scores))\n",
        "    y_pred = (y_scores >= threshold).astype(int)\n",
        "\n",
        "    # Compute metrics\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
        "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
        "\n",
        "    # Compute AUC scores\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    prec, rec, _ = precision_recall_curve(y_true, y_scores)\n",
        "    pr_auc = auc(rec, prec)\n",
        "\n",
        "    performance_data.append({\n",
        "        \"Measure\": measure_name,\n",
        "        \"Optimal Threshold\": threshold,\n",
        "        \"Accuracy\": accuracy,\n",
        "        \"Precision\": precision,\n",
        "        \"Recall\": recall,\n",
        "        \"F1\": f1,\n",
        "        \"ROC-AUC\": roc_auc,\n",
        "        \"PR-AUC\": pr_auc\n",
        "    })\n",
        "\n",
        "# --- Build dataframe safely ---\n",
        "if len(performance_data) == 0:\n",
        "    print(\"‚ùå No valid similarity columns found. Please check final_df contents.\")\n",
        "    print(\"Available columns:\", df_eval.columns.tolist())\n",
        "else:\n",
        "    performance_df = pd.DataFrame(performance_data)\n",
        "    print(\"\\n\", performance_df.to_string(index=False))\n",
        "    performance_df.to_csv(\"performance_comparison.csv\", index=False)\n",
        "    print(\"\\n‚úì Saved: performance_comparison.csv\")\n"
      ],
      "metadata": {
        "id": "2_ez1PWP9NNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "#  Summary\n",
        "# ================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Key Findings:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "best_idx = performance_df[\"F1\"].idxmax()\n",
        "best_measure = performance_df.iloc[best_idx]\n",
        "\n",
        "print(f\"\\nüèÜ Best Performing Measure: {best_measure['Measure']}\")\n",
        "print(f\"  F1 Score : {best_measure['F1']:.4f}\")\n",
        "print(f\"  Accuracy : {best_measure['Accuracy']:.4f}\")\n",
        "print(f\"  Precision: {best_measure['Precision']:.4f}\")\n",
        "print(f\"  Recall   : {best_measure['Recall']:.4f}\")\n",
        "print(f\"  ROC-AUC  : {best_measure['ROC-AUC']:.4f}\")\n",
        "print(f\"  PR-AUC   : {best_measure['PR-AUC']:.4f}\")\n",
        "print(\"\\n\" + \"=\"*60)\n"
      ],
      "metadata": {
        "id": "ofAkvFbq9WVN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}