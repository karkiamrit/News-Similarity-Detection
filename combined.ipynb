{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f17ce837de914e4e8f388dd849c21b96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_83277d511402433db18fd5a0a3c1c334",
              "IPY_MODEL_65ebae662e9f425d8b2426753e5d03b4",
              "IPY_MODEL_6fdd7b7cc424472ba584e966de4414c0"
            ],
            "layout": "IPY_MODEL_de3a6ad282794af984f36bbe3e4c4265"
          }
        },
        "83277d511402433db18fd5a0a3c1c334": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13083f862837474cbae0a0cb390e23cf",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0fc8e2b56efc466693c15bcc2485ced4",
            "value": "Crawling‚Äá+‚ÄáEncoding:‚Äá100%"
          }
        },
        "65ebae662e9f425d8b2426753e5d03b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad45e1b6b46d4988b3e5000161d2d57a",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c3749d99621f44f295933f636970e673",
            "value": 2
          }
        },
        "6fdd7b7cc424472ba584e966de4414c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9bcbf12e1cd84999bc58c6464f5c6103",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_71088dbc5ad24a94831ae07a42ea7de4",
            "value": "‚Äá2/2‚Äá[04:21&lt;00:00,‚Äá153.48s/it]"
          }
        },
        "de3a6ad282794af984f36bbe3e4c4265": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13083f862837474cbae0a0cb390e23cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fc8e2b56efc466693c15bcc2485ced4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad45e1b6b46d4988b3e5000161d2d57a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3749d99621f44f295933f636970e673": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9bcbf12e1cd84999bc58c6464f5c6103": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71088dbc5ad24a94831ae07a42ea7de4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "09b999b437e645e59957a4fc53ded0fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_44cb1b95f7b347ecbe82659ab0b23ac5",
              "IPY_MODEL_6f7d1885c147477a88e1c3e3ea32c871",
              "IPY_MODEL_d57de049a9d4441ba02c73a3b60fc7b1"
            ],
            "layout": "IPY_MODEL_476758f7fbd24d758752f76df3674d38"
          }
        },
        "44cb1b95f7b347ecbe82659ab0b23ac5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5185436d306a4739b15d483aa25f4fa3",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_26815b30f8c94340a2a401eb92eb8c7f",
            "value": "Downloading‚Äáhttps://huggingface.co/stanfordnlp/CoreNLP/resolve/main/stanford-corenlp-latest.zip:‚Äá100%"
          }
        },
        "6f7d1885c147477a88e1c3e3ea32c871": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a66214ec9734034a47bf4b6361e8971",
            "max": 508444875,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1bf1cb85a19345be902255a56b3edab2",
            "value": 508444875
          }
        },
        "d57de049a9d4441ba02c73a3b60fc7b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44984ce54c134f439d167e0340323b4a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0c5b55b5c370440b864c267cc27624b1",
            "value": "‚Äá508M/508M‚Äá[00:01&lt;00:00,‚Äá298MB/s]"
          }
        },
        "476758f7fbd24d758752f76df3674d38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5185436d306a4739b15d483aa25f4fa3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26815b30f8c94340a2a401eb92eb8c7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1a66214ec9734034a47bf4b6361e8971": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bf1cb85a19345be902255a56b3edab2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "44984ce54c134f439d167e0340323b4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c5b55b5c370440b864c267cc27624b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# News Article Similarity Pipeline\n",
        "## Siamese Embedding + 5W1H Extraction\n",
        "\n",
        "---\n",
        "\n",
        "## üìã Overview\n",
        "\n",
        "This pipeline performs two major analytical tasks on news articles:\n",
        "\n",
        "### 1. **Semantic Similarity Analysis**\n",
        "Extracts and compares the first two paragraphs of news articles using:\n",
        "- **SentenceTransformer** (MiniLM) embeddings\n",
        "- **Cosine similarity** metrics\n",
        "\n",
        "### 2. **5W1H Entity Extraction**\n",
        "Run manually in terminal using\n",
        "\n",
        "`java -Xmx4g -cp \"$(echo $HOME/.stanfordnlp_resources/stanford-corenlp-4.5.7/*.jar | tr ' ' ':')\" \\\n",
        "edu.stanford.nlp.pipeline.StanfordCoreNLPServer \\\n",
        "-port 9010 -timeout 500000 \\\n",
        "-annotators tokenize,ssplit,pos,lemma,ner,parse,depparse,coref \\\n",
        "-preload tokenize,ssplit,pos,lemma,ner,parse,depparse,coref \\\n",
        "-coref.algorithm neural\n",
        "`\n",
        "\n",
        "Extracts journalism's fundamental questions from article titles:\n",
        "- **Who** - People/Organizations involved\n",
        "- **What** - Events/Actions that occurred\n",
        "- **When** - Temporal information\n",
        "- **Where** - Locations/Places\n",
        "- **Why** - Reasons/Motivations\n",
        "- **How** - Methods/Processes\n",
        "\n",
        "Uses **Giveme5W1H** library with **Stanford CoreNLP Server** backend.\n",
        "---\n",
        "\n",
        "## üìö Key Libraries\n",
        "\n",
        "- **sentence-transformers**: Neural sentence embeddings\n",
        "- **trafilatura**: Web scraping & text extraction\n",
        "- **Giveme5W1H**: 5W1H entity extraction\n",
        "- **Stanford CoreNLP**: NLP backend for entity recognition\n",
        "- **scikit-learn**: Cosine similarity computation\n"
      ],
      "metadata": {
        "id": "ihqGgWh3ilzG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dependencies and Imports (Siamese)"
      ],
      "metadata": {
        "id": "iYbOgef5mL2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install sentence-transformers trafilatura readability-lxml bs4 lxml html5lib tqdm\n",
        "!pip -q install giveme5w1h geopy"
      ],
      "metadata": {
        "id": "HnEuHGK0p2Mp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "323d97d4-c550-4db2-e909-e8e1080bae87"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/132.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m837.9/837.9 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m315.5/315.5 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m274.7/274.7 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ----------------------------\n",
        "#  Import required libraries\n",
        "# ----------------------------\n",
        "import re, math, time, sys, warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from urllib.parse import urlparse\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import trafilatura\n",
        "from tqdm.auto import tqdm\n",
        "from sentence_transformers import SentenceTransformer"
      ],
      "metadata": {
        "id": "HOJdPus3iYBx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Helper functions\n",
        "\n",
        "> Add blockquote\n",
        "\n"
      ],
      "metadata": {
        "id": "SvIZqLaQmAVk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ----------------------------\n",
        "#  Helper: URL validation\n",
        "# ----------------------------\n",
        "HEADERS = {\"User-Agent\": \"Mozilla/5.0 (compatible; NewsSimilarityBot/1.0; +https://example.org/bot)\"}\n",
        "\n",
        "def is_valid_url(u: str) -> bool:\n",
        "    \"\"\"Check if a given string is a valid HTTP/HTTPS URL.\"\"\"\n",
        "    if not isinstance(u, str) or not u.strip():\n",
        "        return False\n",
        "    p = urlparse(u.strip())\n",
        "    return p.scheme in {\"http\", \"https\"} and bool(p.netloc)\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "#  Extract first two paragraphs from HTML\n",
        "# ----------------------------\n",
        "def first_two_paragraphs_from_html(html: str):\n",
        "    \"\"\"Return the first two meaningful paragraphs from a raw HTML document.\"\"\"\n",
        "    soup = BeautifulSoup(html, \"lxml\")\n",
        "    root = soup.find(\"article\") or soup.find(\"main\") or soup\n",
        "    paras = []\n",
        "    for p in root.find_all(\"p\"):\n",
        "        txt = re.sub(r\"\\s+\", \" \", p.get_text(\" \", strip=True)).strip()\n",
        "        if len(txt) >= 40:  # ignore very short boilerplate text\n",
        "            paras.append(txt)\n",
        "        if len(paras) >= 2:\n",
        "            break\n",
        "    # fallback: if not enough paragraphs found\n",
        "    if len(paras) < 2:\n",
        "        paras = [re.sub(r\"\\s+\", \" \", p.get_text(\" \", strip=True)).strip()\n",
        "                 for p in root.find_all(\"p\") if p.get_text(strip=True)]\n",
        "        paras = [x for x in paras if x][:2]\n",
        "    p1 = paras[0] if len(paras) > 0 else None\n",
        "    p2 = paras[1] if len(paras) > 1 else None\n",
        "    return p1, p2\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "#  Fetch paragraphs (Trafilatura ‚Üí BeautifulSoup fallback)\n",
        "# ----------------------------\n",
        "def fetch_first_two_paragraphs(url: str, timeout=12):\n",
        "    \"\"\"\n",
        "    Try extracting readable text via Trafilatura first,\n",
        "    then fall back to raw HTML parsing using BeautifulSoup.\n",
        "    Returns (p1, p2, status) where status ‚àà {'ok','invalid_url','fetch_error','no_content'}.\n",
        "    \"\"\"\n",
        "    if not is_valid_url(url):\n",
        "        return None, None, \"invalid_url\"\n",
        "\n",
        "    # --- Attempt using Trafilatura ---\n",
        "    try:\n",
        "        downloaded = trafilatura.fetch_url(url, no_ssl=True)\n",
        "        if downloaded:\n",
        "            text = trafilatura.extract(downloaded, include_comments=False, include_tables=False)\n",
        "            if text:\n",
        "                # Split into blocks on blank lines\n",
        "                blocks = [b.strip() for b in re.split(r\"\\n\\s*\\n\", text) if b.strip()]\n",
        "                blocks = [b for b in blocks if len(b) >= 40]\n",
        "                p1 = blocks[0] if len(blocks) > 0 else None\n",
        "                p2 = blocks[1] if len(blocks) > 1 else None\n",
        "                if p1 or p2:\n",
        "                    return p1, p2, \"ok\"\n",
        "    except Exception:\n",
        "        pass  # fallback to HTML parsing\n",
        "\n",
        "    # --- Fallback using raw HTML ---\n",
        "    try:\n",
        "        r = requests.get(url, headers=HEADERS, timeout=timeout)\n",
        "        if r.ok and r.text:\n",
        "            p1, p2 = first_two_paragraphs_from_html(r.text)\n",
        "            if p1 or p2:\n",
        "                return p1, p2, \"ok\"\n",
        "            return None, None, \"no_content\"\n",
        "    except (requests.Timeout, requests.ConnectionError):\n",
        "        # Skip this URL silently if slow or unreachable\n",
        "        return None, None, \"fetch_error\"\n",
        "    except Exception:\n",
        "        return None, None, \"fetch_error\""
      ],
      "metadata": {
        "id": "6BYGxWGLib6L"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Embeddings and similarity *functions*"
      ],
      "metadata": {
        "id": "25Ixn5rkmG-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ----------------------------\n",
        "#  Initialize embedding model\n",
        "# ----------------------------\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "def embed(text: str):\n",
        "    \"\"\"Return a unit-normalized embedding for text.\"\"\"\n",
        "    if not isinstance(text, str) or not text.strip():\n",
        "        return None\n",
        "    v = model.encode([text.strip()], normalize_embeddings=True)[0]\n",
        "    return v\n",
        "\n",
        "def cosine_sim(v1, v2):\n",
        "    \"\"\"Compute cosine similarity between two vectors.\"\"\"\n",
        "    if v1 is None or v2 is None:\n",
        "        return np.nan\n",
        "    return float(np.dot(v1, v2))"
      ],
      "metadata": {
        "id": "Omf41tQ-ifb8"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Load and peek dataset"
      ],
      "metadata": {
        "id": "qNS13vINma0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kudjhnunYwRd",
        "outputId": "206c6880-67e6-411f-ec8e-9175635ce9de"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ================================================================\n",
        "#  STEP 1: Load Dataset\n",
        "# ================================================================\n",
        "# df = pd.read_csv('drive/MyDrive/zenodo_with_url_exists.csv')\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# read from the same directory as combined.ipynb / combined.py\n",
        "base_dir = os.path.dirname(os.path.abspath(__file__)) if \"__file__\" in globals() else os.getcwd()\n",
        "csv_path = os.path.join(base_dir, \"zenodo_with_url_exists.csv\")\n",
        "\n",
        "if not os.path.exists(csv_path):\n",
        "    raise FileNotFoundError(f\"‚ùå Dataset not found: {csv_path}\")\n",
        "\n",
        "df = pd.read_csv(csv_path)\n",
        "print(f\"‚úÖ Loaded {len(df)} rows from {csv_path}\")\n",
        "# Basic info and sanity check\n",
        "print(f\"‚úÖ Loaded {len(df)} rows from zenodo_with_url_exists.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7uc_MIEpz2T",
        "outputId": "bdf45f6a-fa5d-4477-c8a8-f84aff647688"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Loaded 26555 rows from /content/zenodo_with_url_exists.csv\n",
            "‚úÖ Loaded 26555 rows from zenodo_with_url_exists.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()\n",
        "df = df.head(2)"
      ],
      "metadata": {
        "id": "N2L9MpZp4_pJ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### New URL Columns Appended"
      ],
      "metadata": {
        "id": "-Q1QyJPzmhJE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url_cols = [c for c in (\"content.url1\", \"content.url2\") if c in df.columns]\n",
        "\n",
        "# Sanity check: ensure both expected columns exist\n",
        "assert len(url_cols) == 2, (\n",
        "    f\"Expected columns content.url1 & content.url2, but found: {url_cols}\"\n",
        ")\n",
        "print(f\"‚úÖ Found URL columns: {url_cols}\")"
      ],
      "metadata": {
        "id": "4may5-XvmWNJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcd05394-8743-4629-bf4c-8fab3bb32c1d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Found URL columns: ['content.url1', 'content.url2']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Extraction, Embedding and Comparison Using Siamese Model\n",
        " - Extraction of text using helper functions\n",
        " - Embedded text from each set of urls\n",
        " - Calculated cosine similarity using the embeddings\n",
        " - Results Storage and Display\n"
      ],
      "metadata": {
        "id": "ewZrFKAcmqV_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "#  STEP 2: Extract, Embed, and Compare using Siamese Model\n",
        "# ================================================================\n",
        "rows = []\n",
        "\n",
        "for i, row in tqdm(df.iterrows(), total=len(df), desc=\"Crawling + Encoding\"):\n",
        "    u1, u2 = row[url_cols[0]], row[url_cols[1]]\n",
        "\n",
        "    # --- Fetch first 2 paragraphs from both URLs ---\n",
        "    p1a, p1b, s1 = fetch_first_two_paragraphs(u1) if is_valid_url(u1) else (None, None, \"invalid_url\")\n",
        "    p2a, p2b, s2 = fetch_first_two_paragraphs(u2) if is_valid_url(u2) else (None, None, \"invalid_url\")\n",
        "\n",
        "    # --- Combine first + second paragraphs ---\n",
        "    t1 = \" \".join([x for x in (p1a, p1b) if x])\n",
        "    t2 = \" \".join([x for x in (p2a, p2b) if x])\n",
        "\n",
        "    # --- Compute embeddings + cosine similarity ---\n",
        "    v1 = embed(t1)\n",
        "    v2 = embed(t2)\n",
        "    cos = cosine_sim(v1, v2)\n",
        "\n",
        "    rows.append({\n",
        "        \"content.url1\": u1,\n",
        "        \"content.url2\": u2,\n",
        "        \"url1.p1\": p1a, \"url1.p2\": p1b, \"url1.status\": s1,\n",
        "        \"url2.p1\": p2a, \"url2.p2\": p2b, \"url2.status\": s2,\n",
        "        \"siamese.text1\": t1 or None,\n",
        "        \"siamese.text2\": t2 or None,\n",
        "        \"similarity.cosine\": cos,\n",
        "    })\n",
        "\n",
        "# --- Merge results into main dataframe ---\n",
        "result = pd.DataFrame(rows)\n",
        "siamese_output = df.join(result.drop(columns=[\"content.url1\", \"content.url2\"]).set_index(result.index))\n",
        "siamese_output.to_csv(\"siamese_output.csv\", index=False)\n",
        "\n",
        "# --- Preview results instead of saving ---\n",
        "print(\"‚úÖ Siamese comparison complete.\")\n",
        "display(siamese_output.head())\n",
        "print(f\"Total processed pairs: {len(siamese_output)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528,
          "referenced_widgets": [
            "f17ce837de914e4e8f388dd849c21b96",
            "83277d511402433db18fd5a0a3c1c334",
            "65ebae662e9f425d8b2426753e5d03b4",
            "6fdd7b7cc424472ba584e966de4414c0",
            "de3a6ad282794af984f36bbe3e4c4265",
            "13083f862837474cbae0a0cb390e23cf",
            "0fc8e2b56efc466693c15bcc2485ced4",
            "ad45e1b6b46d4988b3e5000161d2d57a",
            "c3749d99621f44f295933f636970e673",
            "9bcbf12e1cd84999bc58c6464f5c6103",
            "71088dbc5ad24a94831ae07a42ea7de4"
          ]
        },
        "id": "6Yhq_-dNjQ3H",
        "outputId": "767e9eeb-b1f8-46a9-fc7f-fcb46a08e37a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Crawling + Encoding:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f17ce837de914e4e8f388dd849c21b96"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö° Skipping slow URL (Trafilatura timeout after 5s): https://www.washingtonpost.com/local/winning-numbers-drawn-in-cash4life-game/2020/01/01/692b3eae-2d06-11ea-bffe-020c88b3f120_story.html\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=0, read=None, redirect=2, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='www.washingtonpost.com', port=443): Read timed out. (read timeout=30)\")': /local/winning-numbers-drawn-in-cash4life-game/2020/01/01/692b3eae-2d06-11ea-bffe-020c88b3f120_story.html\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=0, read=None, redirect=2, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='www.washingtonpost.com', port=443): Read timed out. (read timeout=30)\")': /local/winning-numbers-drawn-in-cash4life-game/2020/01/01/692b3eae-2d06-11ea-bffe-020c88b3f120_story.html\n",
            "ERROR:trafilatura.downloads:download error: https://www.washingtonpost.com/local/winning-numbers-drawn-in-cash4life-game/2020/01/01/692b3eae-2d06-11ea-bffe-020c88b3f120_story.html HTTPSConnectionPool(host='www.washingtonpost.com', port=443): Max retries exceeded with url: /local/winning-numbers-drawn-in-cash4life-game/2020/01/01/692b3eae-2d06-11ea-bffe-020c88b3f120_story.html (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='www.washingtonpost.com', port=443): Read timed out. (read timeout=30)\"))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö° Skipping slow URL (Trafilatura timeout after 5s): https://www.washingtonpost.com/world/the_americas/haitis-leader-marks-independence-day-amid-security-concerns/2020/01/01/dc4033a4-2cc5-11ea-bffe-020c88b3f120_story.html\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=0, read=None, redirect=2, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='www.washingtonpost.com', port=443): Read timed out. (read timeout=30)\")': /world/the_americas/haitis-leader-marks-independence-day-amid-security-concerns/2020/01/01/dc4033a4-2cc5-11ea-bffe-020c88b3f120_story.html\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=0, read=None, redirect=2, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='www.washingtonpost.com', port=443): Read timed out. (read timeout=30)\")': /world/the_americas/haitis-leader-marks-independence-day-amid-security-concerns/2020/01/01/dc4033a4-2cc5-11ea-bffe-020c88b3f120_story.html\n",
            "ERROR:trafilatura.downloads:download error: https://www.washingtonpost.com/world/the_americas/haitis-leader-marks-independence-day-amid-security-concerns/2020/01/01/dc4033a4-2cc5-11ea-bffe-020c88b3f120_story.html HTTPSConnectionPool(host='www.washingtonpost.com', port=443): Max retries exceeded with url: /world/the_americas/haitis-leader-marks-independence-day-amid-security-concerns/2020/01/01/dc4033a4-2cc5-11ea-bffe-020c88b3f120_story.html (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='www.washingtonpost.com', port=443): Read timed out. (read timeout=30)\"))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Siamese comparison complete.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   Unnamed: 0        content.pair_id  content.similarity  \\\n",
              "0           0  1484188922_1484188392            0.141053   \n",
              "1           1  1484299489_1484110209            0.243056   \n",
              "\n",
              "                                        content.url1  \\\n",
              "0  https://www.marshallindependent.com/news/local...   \n",
              "1  https://www.washingtonpost.com/local/winning-n...   \n",
              "\n",
              "                                        content.url2  \\\n",
              "0  https://www.austin360.com/entertainment/201912...   \n",
              "1  https://www.washingtonpost.com/world/the_ameri...   \n",
              "\n",
              "                                      content.title1  \\\n",
              "0  New brewery  in Sleepy Eye draws a crowd , Spo...   \n",
              "1          Winning numbers drawn in ‚ÄòCash4Life‚Äô game   \n",
              "\n",
              "                                      content.title2 real_lang1 real_lang2  \\\n",
              "0  New North Austin brewery, Hopsquad, opens befo...         en         en   \n",
              "1  Haiti‚Äôs leader marks independence day amid sec...         en         en   \n",
              "\n",
              "               GEO  ... url2_exists  \\\n",
              "0  Very Dissimilar  ...        True   \n",
              "1  Very Dissimilar  ...       False   \n",
              "\n",
              "                                             url1.p1 url1.p2  url1.status  \\\n",
              "0  New brewery in Sleepy Eye draws a crowd\\nSLEEP...    None           ok   \n",
              "1                                               None    None  fetch_error   \n",
              "\n",
              "                                             url2.p1 url2.p2  url2.status  \\\n",
              "0  MusicHow Billie Eilish is changing concert cul...    None           ok   \n",
              "1                                               None    None  fetch_error   \n",
              "\n",
              "                                       siamese.text1  \\\n",
              "0  New brewery in Sleepy Eye draws a crowd\\nSLEEP...   \n",
              "1                                               None   \n",
              "\n",
              "                                       siamese.text2  similarity.cosine  \n",
              "0  MusicHow Billie Eilish is changing concert cul...           0.261238  \n",
              "1                                               None                NaN  \n",
              "\n",
              "[2 rows x 38 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-20209e58-ec5e-4461-88c2-2ec740121001\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>content.pair_id</th>\n",
              "      <th>content.similarity</th>\n",
              "      <th>content.url1</th>\n",
              "      <th>content.url2</th>\n",
              "      <th>content.title1</th>\n",
              "      <th>content.title2</th>\n",
              "      <th>real_lang1</th>\n",
              "      <th>real_lang2</th>\n",
              "      <th>GEO</th>\n",
              "      <th>...</th>\n",
              "      <th>url2_exists</th>\n",
              "      <th>url1.p1</th>\n",
              "      <th>url1.p2</th>\n",
              "      <th>url1.status</th>\n",
              "      <th>url2.p1</th>\n",
              "      <th>url2.p2</th>\n",
              "      <th>url2.status</th>\n",
              "      <th>siamese.text1</th>\n",
              "      <th>siamese.text2</th>\n",
              "      <th>similarity.cosine</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1484188922_1484188392</td>\n",
              "      <td>0.141053</td>\n",
              "      <td>https://www.marshallindependent.com/news/local...</td>\n",
              "      <td>https://www.austin360.com/entertainment/201912...</td>\n",
              "      <td>New brewery  in Sleepy Eye draws a crowd , Spo...</td>\n",
              "      <td>New North Austin brewery, Hopsquad, opens befo...</td>\n",
              "      <td>en</td>\n",
              "      <td>en</td>\n",
              "      <td>Very Dissimilar</td>\n",
              "      <td>...</td>\n",
              "      <td>True</td>\n",
              "      <td>New brewery in Sleepy Eye draws a crowd\\nSLEEP...</td>\n",
              "      <td>None</td>\n",
              "      <td>ok</td>\n",
              "      <td>MusicHow Billie Eilish is changing concert cul...</td>\n",
              "      <td>None</td>\n",
              "      <td>ok</td>\n",
              "      <td>New brewery in Sleepy Eye draws a crowd\\nSLEEP...</td>\n",
              "      <td>MusicHow Billie Eilish is changing concert cul...</td>\n",
              "      <td>0.261238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1484299489_1484110209</td>\n",
              "      <td>0.243056</td>\n",
              "      <td>https://www.washingtonpost.com/local/winning-n...</td>\n",
              "      <td>https://www.washingtonpost.com/world/the_ameri...</td>\n",
              "      <td>Winning numbers drawn in ‚ÄòCash4Life‚Äô game</td>\n",
              "      <td>Haiti‚Äôs leader marks independence day amid sec...</td>\n",
              "      <td>en</td>\n",
              "      <td>en</td>\n",
              "      <td>Very Dissimilar</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>fetch_error</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>fetch_error</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows √ó 38 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-20209e58-ec5e-4461-88c2-2ec740121001')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-20209e58-ec5e-4461-88c2-2ec740121001 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-20209e58-ec5e-4461-88c2-2ec740121001');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-8540bdad-62fb-4b1e-9e09-2012c091efa0\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8540bdad-62fb-4b1e-9e09-2012c091efa0')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-8540bdad-62fb-4b1e-9e09-2012c091efa0 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total processed pairs: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Final Result Siamese"
      ],
      "metadata": {
        "id": "h6OsplJesr5B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "siamese_output.head()"
      ],
      "metadata": {
        "id": "CcpPykIIskws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PsRLCOHJnV2k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dependencies and Imports (5W1H)"
      ],
      "metadata": {
        "id": "6T4IosABoJj4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "import time\n",
        "import requests\n",
        "import zipfile\n",
        "from datetime import datetime, timezone\n",
        "from Giveme5W1H.extractor.extractor import MasterExtractor\n",
        "from Giveme5W1H.extractor.document import Document\n",
        "from Giveme5W1H.extractor.extractors.environment_extractor import EnvironmentExtractor\n",
        "from Giveme5W1H.extractor.preprocessors.preprocessor_core_nlp import Preprocessor\n",
        "from geopy.geocoders import options\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "wIdb3EE1jUu0"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Giveme5W1H extractor and CoreNLP preprocessor setup"
      ],
      "metadata": {
        "id": "mu5kepsQo_rF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Install Dependencies and initialize stanza"
      ],
      "metadata": {
        "id": "uVkMIMH71toZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Java and stanza\n",
        "!apt-get update -q\n",
        "!apt-get install -y openjdk-17-jdk unzip wget -q\n",
        "!pip install stanza requests -q\n",
        "\n",
        "# Download and install CoreNLP via stanza helper\n",
        "import stanza\n",
        "stanza.install_corenlp()   # This will download stanford-corenlp-4.5.5 to ~/.stanfordnlp_resources/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "09b999b437e645e59957a4fc53ded0fc",
            "44cb1b95f7b347ecbe82659ab0b23ac5",
            "6f7d1885c147477a88e1c3e3ea32c871",
            "d57de049a9d4441ba02c73a3b60fc7b1",
            "476758f7fbd24d758752f76df3674d38",
            "5185436d306a4739b15d483aa25f4fa3",
            "26815b30f8c94340a2a401eb92eb8c7f",
            "1a66214ec9734034a47bf4b6361e8971",
            "1bf1cb85a19345be902255a56b3edab2",
            "44984ce54c134f439d167e0340323b4a",
            "0c5b55b5c370440b864c267cc27624b1"
          ]
        },
        "id": "z0gLlbRGxaiw",
        "outputId": "e36fcdbc-5af3-484a-e30b-9edb31745255"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hit:1 https://cli.github.com/packages stable InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists...\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "unzip is already the newest version (6.0-26ubuntu3.2).\n",
            "wget is already the newest version (1.21.2-2ubuntu1.1).\n",
            "The following additional packages will be installed:\n",
            "  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java\n",
            "  libatk-wrapper-java-jni libxt-dev libxtst6 libxxf86dga1 openjdk-17-jre\n",
            "  x11-utils\n",
            "Suggested packages:\n",
            "  libxt-doc openjdk-17-demo openjdk-17-source visualvm mesa-utils\n",
            "The following NEW packages will be installed:\n",
            "  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java\n",
            "  libatk-wrapper-java-jni libxt-dev libxtst6 libxxf86dga1 openjdk-17-jdk\n",
            "  openjdk-17-jre x11-utils\n",
            "0 upgraded, 10 newly installed, 0 to remove and 47 not upgraded.\n",
            "Need to get 5,566 kB of archives.\n",
            "After this operation, 15.5 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-core all 2.37-2build1 [1,041 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-extra all 2.37-2build1 [2,041 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxtst6 amd64 2:1.2.3-1build4 [13.4 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxxf86dga1 amd64 2:1.1.5-0ubuntu3 [12.6 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-utils amd64 7.7+5build2 [206 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java all 0.38.0-5build1 [53.1 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-wrapper-java-jni amd64 0.38.0-5build1 [49.0 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxt-dev amd64 1:1.2.1-1 [396 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-17-jre amd64 17.0.16+8~us1-0ubuntu1~22.04.1 [232 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-17-jdk amd64 17.0.16+8~us1-0ubuntu1~22.04.1 [1,522 kB]\n",
            "Fetched 5,566 kB in 2s (2,794 kB/s)\n",
            "Selecting previously unselected package fonts-dejavu-core.\n",
            "(Reading database ... 125548 files and directories currently installed.)\n",
            "Preparing to unpack .../0-fonts-dejavu-core_2.37-2build1_all.deb ...\n",
            "Unpacking fonts-dejavu-core (2.37-2build1) ...\n",
            "Selecting previously unselected package fonts-dejavu-extra.\n",
            "Preparing to unpack .../1-fonts-dejavu-extra_2.37-2build1_all.deb ...\n",
            "Unpacking fonts-dejavu-extra (2.37-2build1) ...\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "Preparing to unpack .../2-libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package libxxf86dga1:amd64.\n",
            "Preparing to unpack .../3-libxxf86dga1_2%3a1.1.5-0ubuntu3_amd64.deb ...\n",
            "Unpacking libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
            "Selecting previously unselected package x11-utils.\n",
            "Preparing to unpack .../4-x11-utils_7.7+5build2_amd64.deb ...\n",
            "Unpacking x11-utils (7.7+5build2) ...\n",
            "Selecting previously unselected package libatk-wrapper-java.\n",
            "Preparing to unpack .../5-libatk-wrapper-java_0.38.0-5build1_all.deb ...\n",
            "Unpacking libatk-wrapper-java (0.38.0-5build1) ...\n",
            "Selecting previously unselected package libatk-wrapper-java-jni:amd64.\n",
            "Preparing to unpack .../6-libatk-wrapper-java-jni_0.38.0-5build1_amd64.deb ...\n",
            "Unpacking libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n",
            "Selecting previously unselected package libxt-dev:amd64.\n",
            "Preparing to unpack .../7-libxt-dev_1%3a1.2.1-1_amd64.deb ...\n",
            "Unpacking libxt-dev:amd64 (1:1.2.1-1) ...\n",
            "Selecting previously unselected package openjdk-17-jre:amd64.\n",
            "Preparing to unpack .../8-openjdk-17-jre_17.0.16+8~us1-0ubuntu1~22.04.1_amd64.deb ...\n",
            "Unpacking openjdk-17-jre:amd64 (17.0.16+8~us1-0ubuntu1~22.04.1) ...\n",
            "Selecting previously unselected package openjdk-17-jdk:amd64.\n",
            "Preparing to unpack .../9-openjdk-17-jdk_17.0.16+8~us1-0ubuntu1~22.04.1_amd64.deb ...\n",
            "Unpacking openjdk-17-jdk:amd64 (17.0.16+8~us1-0ubuntu1~22.04.1) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up libxxf86dga1:amd64 (2:1.1.5-0ubuntu3) ...\n",
            "Setting up libxt-dev:amd64 (1:1.2.1-1) ...\n",
            "Setting up fonts-dejavu-core (2.37-2build1) ...\n",
            "Setting up fonts-dejavu-extra (2.37-2build1) ...\n",
            "Setting up x11-utils (7.7+5build2) ...\n",
            "Setting up libatk-wrapper-java (0.38.0-5build1) ...\n",
            "Setting up openjdk-17-jre:amd64 (17.0.16+8~us1-0ubuntu1~22.04.1) ...\n",
            "Setting up openjdk-17-jdk:amd64 (17.0.16+8~us1-0ubuntu1~22.04.1) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jconsole to provide /usr/bin/jconsole (jconsole) in auto mode\n",
            "Setting up libatk-wrapper-java-jni:amd64 (0.38.0-5build1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:stanza:Installing CoreNLP package into /root/stanza_corenlp\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading https://huggingface.co/stanfordnlp/CoreNLP/resolve/main/stanford-corenlp-latest.zip:   0%|        ‚Ä¶"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "09b999b437e645e59957a4fc53ded0fc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:stanza:Downloaded file to /root/stanza_corenlp/corenlp.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from stanza.server import CoreNLPClient\n",
        "\n",
        "# with CoreNLPClient(\n",
        "#     annotators=['tokenize','ssplit','pos','lemma','ner','parse','depparse'],\n",
        "#     timeout=60000,\n",
        "#     memory='2G',\n",
        "#     be_quiet=False\n",
        "# ) as client:\n",
        "#     ann = client.annotate(\"Barack Obama was born in Hawaii.\")\n",
        "#     print(ann)"
      ],
      "metadata": {
        "id": "dzyogJYvxQB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Connect to preprocessor server and configure Giveme5W1H extractor"
      ],
      "metadata": {
        "id": "FnwnX1Za13LR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def download_and_setup_corenlp():\n",
        "    \"\"\"Download and extract Stanford CoreNLP.\"\"\"\n",
        "    base_path = os.path.expanduser(\"~/.stanfordnlp_resources\")\n",
        "    corenlp_version = \"4.5.7\"\n",
        "    corenlp_dir = f\"{base_path}/stanford-corenlp-{corenlp_version}\"\n",
        "    os.makedirs(base_path, exist_ok=True)\n",
        "\n",
        "    if os.path.exists(corenlp_dir):\n",
        "        print(f\"‚úì CoreNLP already exists at {corenlp_dir}\")\n",
        "        return corenlp_dir\n",
        "\n",
        "    # Download CoreNLP\n",
        "    url = f\"https://nlp.stanford.edu/software/stanford-corenlp-{corenlp_version}.zip\"\n",
        "    zip_path = f\"{base_path}/stanford-corenlp-{corenlp_version}.zip\"\n",
        "    print(f\"‚¨áÔ∏è  Downloading CoreNLP {corenlp_version} (~500 MB)...\")\n",
        "\n",
        "    result = subprocess.run([\"wget\", \"-q\", \"--show-progress\", url, \"-O\", zip_path])\n",
        "    if result.returncode != 0:\n",
        "        raise RuntimeError(f\"Failed to download CoreNLP from {url}\")\n",
        "\n",
        "    print(\"üì¶ Extracting CoreNLP...\")\n",
        "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "        zip_ref.extractall(base_path)\n",
        "    os.remove(zip_path)\n",
        "\n",
        "    print(f\"‚úì CoreNLP installed at {corenlp_dir}\")\n",
        "    return corenlp_dir\n",
        "\n",
        "\n",
        "def start_corenlp_server(corenlp_home, port=9020):\n",
        "    \"\"\"Start CoreNLP server in background.\"\"\"\n",
        "    try:\n",
        "        requests.get(f\"http://127.0.0.1:{port}\", timeout=2)\n",
        "        print(f\"‚úì CoreNLP server already running on port {port}\")\n",
        "        return\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    print(f\"üöÄ Starting CoreNLP server on port {port}...\")\n",
        "    cmd = [\n",
        "          \"java\", \"-Xmx4g\",\n",
        "          \"-cp\", f\"{corenlp_home}/*\",\n",
        "          \"edu.stanford.nlp.pipeline.StanfordCoreNLPServer\",\n",
        "          \"--port\", str(port),\n",
        "          \"--timeout\", \"500000\",\n",
        "          \"--annotators\", \"tokenize,ssplit,pos,lemma,ner,parse,depparse,coref\",\n",
        "          \"--preload\", \"tokenize,ssplit,pos,lemma,ner,parse,depparse,coref\",\n",
        "          \"--coref.algorithm\", \"neural\"\n",
        "      ]\n",
        "    process = subprocess.Popen(cmd, cwd=corenlp_home,\n",
        "                               stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "\n",
        "    print(\"‚è≥ Waiting for server to start\", end=\"\")\n",
        "    for i in range(90):\n",
        "        try:\n",
        "            requests.get(f\"http://127.0.0.1:{port}\", timeout=2)\n",
        "            print(f\"\\n‚úì CoreNLP server started successfully (took {i+1}s)\")\n",
        "            return\n",
        "        except Exception:\n",
        "            print(\".\", end=\"\", flush=True)\n",
        "            time.sleep(1)\n",
        "    raise RuntimeError(\"‚ùå Failed to start CoreNLP server after 90 s\")\n",
        "\n"
      ],
      "metadata": {
        "id": "ptCPUbiB3Gb8"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initialize Giveme5W1H extractor and CoreNLP preprocessor\n",
        "corenlp_home = download_and_setup_corenlp()\n",
        "# start_corenlp_server(corenlp_home, port=9020) only if not manually ran\n",
        "options.default_user_agent = \"colab-giveme5w1h\"\n",
        "try:\n",
        "  pre = Preprocessor(\"http://127.0.0.1:9020\")  # assumes CoreNLP server is running\n",
        "  pre._Preprocessor__default_annotators = \"tokenize,ssplit,pos,lemma,ner,parse,depparse,coref\"\n",
        "\n",
        "  print(\"‚úÖ CoreNLP server is running!\")\n",
        "except Exception as e:\n",
        "    print(\"‚ùå CoreNLP server not reachable:\", e)\n",
        "\n",
        "extractor = MasterExtractor(preprocessor=pre)\n",
        "\n",
        "# remove environment extractor for speed\n",
        "extractor.extractors = [e for e in extractor.extractors if not isinstance(e, EnvironmentExtractor)]\n",
        "\n",
        "TITLE_COLS = [c for c in (\"content.title1\", \"content.title2\") if c in df.columns]"
      ],
      "metadata": {
        "id": "UWQkhnmz5y3m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b3d9e9b-a14a-4389-eb11-97f6af5a5d88"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:GiveMe5W:Could not find corpus for WordNet, will now try to download the corpus.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì CoreNLP already exists at /root/.stanfordnlp_resources/stanford-corenlp-4.5.7\n",
            "‚úÖ CoreNLP server is running!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helper function to extract 5w1h from title and process it"
      ],
      "metadata": {
        "id": "YtOMwQzxpOlf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Sanitize Title\n"
      ],
      "metadata": {
        "id": "5R8Djr-0Gr_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import html, re, json\n",
        "\n",
        "def sanitize_title(title: str) -> str:\n",
        "    \"\"\"Clean up titles for better NLP parsing.\"\"\"\n",
        "    title = re.sub(r'\\s+', ' ', title)\n",
        "    title = re.sub(r'[^\\w\\s,\\'\"-]', '', title)\n",
        "    return title.strip()"
      ],
      "metadata": {
        "id": "4Olx_6i2GvTI"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ner_fallback(text: str):\n",
        "    \"\"\"Fallback extractor using CoreNLP NER for short texts.\"\"\"\n",
        "    props = {\"annotators\": \"tokenize,ssplit,pos,lemma,ner\", \"outputFormat\": \"json\"}\n",
        "    try:\n",
        "        r = requests.post(\n",
        "            \"http://127.0.0.1:9020\",\n",
        "            params={\"properties\": json.dumps(props)},\n",
        "            data=text.encode(\"utf-8\"),\n",
        "            headers={\"Content-Type\": \"text/plain; charset=utf-8\"},\n",
        "            timeout=15\n",
        "        )\n",
        "        data = r.json()\n",
        "        entities = [(ent[\"text\"], ent[\"ner\"])\n",
        "                    for sent in data.get(\"sentences\", [])\n",
        "                    for ent in sent.get(\"entitymentions\", [])]\n",
        "\n",
        "        who = \" \".join([t for t, n in entities if n in {\"PERSON\", \"ORGANIZATION\"}]) or None\n",
        "        where = \" \".join([t for t, n in entities if n in {\"LOCATION\", \"CITY\", \"STATE_OR_PROVINCE\", \"COUNTRY\"}]) or None\n",
        "        when = \" \".join([t for t, n in entities if n in {\"DATE\", \"TIME\"}]) or None\n",
        "\n",
        "        what = re.sub(r\"[^\\w\\s,'-]\", \"\", text).strip() or None\n",
        "        return {\"who\": who, \"what\": what, \"when\": when, \"where\": where, \"why\": None, \"how\": None}\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå NER fallback failed: {e}\")\n",
        "        return {k: None for k in [\"who\", \"what\", \"when\", \"where\", \"why\", \"how\"]}\n",
        "\n",
        "\n",
        "def extract_5w1h_from_title(title: str):\n",
        "    \"\"\"Main extractor with GiveMe5W1H + fallback.\"\"\"\n",
        "    if not isinstance(title, str) or not title.strip():\n",
        "        return {k: None for k in [\"who\", \"what\", \"when\", \"where\", \"why\", \"how\"]}\n",
        "    try:\n",
        "        doc = Document.from_text(title)\n",
        "        doc = extractor.parse(doc)\n",
        "        def safe_extract(q):\n",
        "            try:\n",
        "                return doc.get_top_answer(q).get_parts_as_text()\n",
        "            except Exception:\n",
        "                return None\n",
        "        result = {q: safe_extract(q) for q in [\"who\", \"what\", \"when\", \"where\", \"why\", \"how\"]}\n",
        "        if all(v is None for v in result.values()):\n",
        "            result.update(ner_fallback(title))\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Fallback triggered for '{title[:60]}...': {e}\")\n",
        "        return ner_fallback(title)\n",
        "\n"
      ],
      "metadata": {
        "id": "xWTXwvI9jbOl"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(extract_5w1h_from_title(\"Porter‚Äôs factor conditions for countries‚Äô competitiveness are demand condition, related industries, firm‚Äôs strategy, and the level of rivalry. Australia has been challenged for the trophy and there was an increased demand for the country to produce results in the game. The country through several failures to lift the trophy had learned its weaknesses, and in 2005, it went to the games with polished strategies to face their rivals. This led to its victory.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KnvkCiqt9nA",
        "outputId": "3f34fd44-e916-43d4-9238-e657ec6be63d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö†Ô∏è Fallback triggered for 'Porter‚Äôs factor conditions for countries‚Äô competitiveness ar...': Could not handle incoming annotation\n",
            "{'who': 'Porter', 'what': 'Porters factor conditions for countries competitiveness are demand condition, related industries, firms strategy, and the level of rivalry Australia has been challenged for the trophy and there was an increased demand for the country to produce results in the game The country through several failures to lift the trophy had learned its weaknesses, and in 2005, it went to the games with polished strategies to face their rivals This led to its victory', 'when': '2005', 'where': 'Australia', 'why': None, 'how': None}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Text Extraction"
      ],
      "metadata": {
        "id": "iDa5L9HHprw_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# STEP 3: Apply Across Titles\n",
        "# ============================================================\n",
        "def process_titles_once(df, title_cols):\n",
        "    \"\"\"Apply 5W1H extraction to all given title columns with progress tracking.\"\"\"\n",
        "    result_df = df.copy()\n",
        "    for col in title_cols:\n",
        "        if col not in result_df.columns:\n",
        "            print(f\"‚ö†Ô∏è Skipping {col}: not found in dataframe\")\n",
        "            continue\n",
        "\n",
        "        print(f\"\\nüöÄ Processing {col} ({len(result_df)} titles)\")\n",
        "        results = []\n",
        "        for idx, title in enumerate(result_df[col].fillna(\"\")):\n",
        "            if idx % 10 == 0:\n",
        "                print(f\"  ‚Üí Progress: {idx}/{len(result_df)}\", end=\"\\r\")\n",
        "            if idx % 100 == 0 and idx > 0:\n",
        "                time.sleep(0.3)\n",
        "\n",
        "            clean_title = re.sub(r\"\\s+\", \" \", str(title)).strip()\n",
        "            if clean_title:\n",
        "                results.append(extract_5w1h_from_title(clean_title))\n",
        "            else:\n",
        "                results.append({k: None for k in [\"who\", \"what\", \"when\", \"where\", \"why\", \"how\"]})\n",
        "\n",
        "        col_results = pd.DataFrame.from_records(results, index=result_df.index)\n",
        "        for q in col_results.columns:\n",
        "            result_df[f\"{col}.{q}\"] = col_results[q].values\n",
        "        print(f\"‚úÖ Completed {col} ({len(result_df)} titles)\")\n",
        "\n",
        "    result_df = result_df.loc[:, ~result_df.columns.duplicated(keep=\"last\")]\n",
        "    return result_df\n"
      ],
      "metadata": {
        "id": "EfWFAlcLlYED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Starting 5W1H extraction...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "TITLE_COLS = [c for c in (\"content.title1\", \"content.title2\") if c in df.columns]\n",
        "result_df = process_titles_once(df, TITLE_COLS)\n",
        "\n",
        "preview_cols = [f\"{c}.{q}\" for c in TITLE_COLS for q in (\"who\",\"what\",\"when\",\"where\",\"why\",\"how\")]\n",
        "keep = [c for c in [\"content.url1\",\"content.url2\",\"content.title1\",\"content.title2\"] if c in result_df.columns] + [c for c in preview_cols if c in result_df.columns]\n",
        "result_df = result_df[keep]"
      ],
      "metadata": {
        "id": "7jQUm99cjc_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing the connection\n",
        "# import requests, json\n",
        "# text = sanitize_title(\"NASA launches Artemis mission to the Moon\")\n",
        "# props = {\n",
        "#     \"annotators\": \"tokenize,ssplit,pos,lemma,ner\",\n",
        "#     \"outputFormat\": \"json\"\n",
        "# }\n",
        "# r = requests.post(\n",
        "#     \"http://127.0.0.1:9010\",\n",
        "#     params={\"properties\": json.dumps(props)},\n",
        "#     data=text.encode(\"utf-8\"),\n",
        "#     headers={\"Content-Type\": \"text/plain; charset=utf-8\"}\n",
        "# )\n",
        "# print(r.status_code)\n",
        "# print(r.text[:300])\n"
      ],
      "metadata": {
        "id": "i7mJh1nmIExa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Save and Display results"
      ],
      "metadata": {
        "id": "DbKBSKZ9pukc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(result_df.head())\n",
        "fivew1h_output = result_df\n",
        "fivew1h_output.to_csv(\"fivew1h_output.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "SGzgG3jepmxE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "d5917868-e7bd-465a-80c8-ddf7c9314ce2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'result_df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2578594005.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfivew1h_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfivew1h_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fivew1h_output.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'result_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Entity Based Similarity & Fusion with Siamese Network"
      ],
      "metadata": {
        "id": "tVlFvF0C6H97"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.spatial.distance import euclidean\n",
        "from scipy.stats import pearsonr"
      ],
      "metadata": {
        "id": "XkKgUUFp6UKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the previous 5W1H output directly (not from CSV)\n",
        "# fivew1h_output already has content.title1.*, content.title2.* columns\n",
        "fusion_df = fivew1h_output.copy()"
      ],
      "metadata": {
        "id": "0MKFL-7E6XK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- Helper functions ---\n",
        "def calculate_entity_overlap(entity1, entity2):\n",
        "    \"\"\"Calculate overlap between two entities (Jaccard similarity).\"\"\"\n",
        "    if not entity1 or not entity2:\n",
        "        return 0.0\n",
        "\n",
        "    set1 = set(str(entity1).lower().split())\n",
        "    set2 = set(str(entity2).lower().split())\n",
        "\n",
        "    if len(set1) == 0 and len(set2) == 0:\n",
        "        return 1.0\n",
        "    if len(set1) == 0 or len(set2) == 0:\n",
        "        return 0.0\n",
        "\n",
        "    intersection = len(set1.intersection(set2))\n",
        "    union = len(set1.union(set2))\n",
        "    return intersection / union if union > 0 else 0.0\n",
        "\n",
        "def calculate_5w1h_similarity(row):\n",
        "    \"\"\"Calculate entity-based similarity for a pair of articles.\"\"\"\n",
        "    questions = ['who', 'what', 'when', 'where', 'why', 'how']\n",
        "    similarities = {}\n",
        "\n",
        "    for q in questions:\n",
        "        col1 = f'content.title1.{q}'\n",
        "        col2 = f'content.title2.{q}'\n",
        "\n",
        "        if col1 in row.index and col2 in row.index:\n",
        "            entity1 = row[col1]\n",
        "            entity2 = row[col2]\n",
        "            similarities[q] = calculate_entity_overlap(entity1, entity2)\n",
        "        else:\n",
        "            similarities[q] = 0.0\n",
        "\n",
        "    avg_entity_sim = np.mean(list(similarities.values()))\n",
        "    return pd.Series({\n",
        "        'entity_who_sim': similarities['who'],\n",
        "        'entity_what_sim': similarities['what'],\n",
        "        'entity_when_sim': similarities['when'],\n",
        "        'entity_where_sim': similarities['where'],\n",
        "        'entity_why_sim': similarities['why'],\n",
        "        'entity_how_sim': similarities['how'],\n",
        "        'avg_entity_similarity': avg_entity_sim\n",
        "    })\n",
        "\n",
        "# --- Apply entity similarity computation ---\n",
        "entity_similarities = fusion_df.apply(calculate_5w1h_similarity, axis=1)\n",
        "fusion_df = pd.concat([fusion_df, entity_similarities], axis=1)\n",
        "\n",
        "print(\"‚úì Entity-based similarities calculated successfully.\")\n",
        "\n",
        "# Handle duplicated or non-standard column safely\n",
        "if 'avg_entity_similarity' in fusion_df.columns:\n",
        "    # If there are duplicate columns, keep only the last one\n",
        "    if isinstance(fusion_df['avg_entity_similarity'], pd.DataFrame):\n",
        "        avg_sim_col = fusion_df['avg_entity_similarity'].iloc[:, -1]\n",
        "    else:\n",
        "        avg_sim_col = fusion_df['avg_entity_similarity']\n",
        "\n",
        "    # Ensure Series is flat numeric\n",
        "    avg_sim_flat = pd.to_numeric(avg_sim_col.astype(str).str.extract(r'([\\d.]+)')[0], errors='coerce')\n",
        "    mean_val = float(avg_sim_flat.mean()) if not avg_sim_flat.isna().all() else 0.0\n",
        "    print(f\"  - Average entity similarity across dataset: {mean_val:.4f}\")\n",
        "else:\n",
        "    print(\"  - Warning: avg_entity_similarity column not found.\")\n",
        "# --- Preview output ---\n",
        "preview_cols = [\n",
        "    \"content.url1\", \"content.url2\",\n",
        "    \"content.title1\", \"content.title2\",\n",
        "    \"avg_entity_similarity\", \"entity_who_sim\", \"entity_what_sim\", \"entity_when_sim\",\n",
        "    \"entity_where_sim\", \"entity_why_sim\", \"entity_how_sim\"\n",
        "]\n",
        "print(\"\\nSample output:\")\n",
        "display(fusion_df[preview_cols].head())\n",
        "\n",
        "# For later fusion with Siamese results\n",
        "entity_output = fusion_df\n"
      ],
      "metadata": {
        "id": "FpFd1Ap66c_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### STEP 5: Fusion Layer (Entity + Embedding Similarity)"
      ],
      "metadata": {
        "id": "iHnjaAvz6uKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "#  STEP 5: Fusion Layer ‚Äî Combine Entity and Siamese Similarities\n",
        "# ================================================================\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 5: Fusion Layer (Entity + Siamese Network)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# --- Merge Siamese and Entity-based results ---\n",
        "fusion_df = pd.merge(\n",
        "    siamese_output,\n",
        "    entity_output[[\"content.url1\", \"content.url2\", \"avg_entity_similarity\"]],\n",
        "    on=[\"content.url1\", \"content.url2\"],\n",
        "    how=\"left\"\n",
        ")\n",
        "\n",
        "# --- Rename for clarity ---\n",
        "fusion_df = fusion_df.loc[:, ~fusion_df.columns.duplicated()]  # remove duplicates\n",
        "fusion_df.rename(columns={\"similarity.cosine\": \"siamese_similarity\"}, inplace=True)\n",
        "\n",
        "# --- Ensure numeric columns ---\n",
        "fusion_df[\"avg_entity_similarity\"] = pd.to_numeric(\n",
        "    fusion_df[\"avg_entity_similarity\"], errors=\"coerce\"\n",
        ").fillna(0)\n",
        "fusion_df[\"siamese_similarity\"] = pd.to_numeric(\n",
        "    fusion_df[\"siamese_similarity\"], errors=\"coerce\"\n",
        ").fillna(0)\n",
        "\n",
        "# --- Define fusion function ---\n",
        "def fusion_similarity(entity_sim, siamese_sim, entity_weight=0.4, siamese_weight=0.6):\n",
        "    \"\"\"Combine entity-based and embedding-based (Siamese) similarities.\"\"\"\n",
        "    return (entity_weight * entity_sim) + (siamese_weight * siamese_sim)\n",
        "\n",
        "# --- Compute fusion vectorized (faster & safer than .apply) ---\n",
        "fusion_df[\"fused_similarity\"] = fusion_similarity(\n",
        "    fusion_df[\"avg_entity_similarity\"],\n",
        "    fusion_df[\"siamese_similarity\"],\n",
        "    entity_weight=0.4,\n",
        "    siamese_weight=0.6,\n",
        ")\n",
        "\n",
        "# --- Summary statistics ---\n",
        "mean_val = fusion_df[\"fused_similarity\"].mean()\n",
        "print(\"‚úì Fusion similarity calculated successfully.\")\n",
        "print(f\"  - Average fused similarity: {mean_val:.4f}\")\n",
        "print(f\"  - Min fused similarity: {fusion_df['fused_similarity'].min():.4f}\")\n",
        "print(f\"  - Max fused similarity: {fusion_df['fused_similarity'].max():.4f}\")\n",
        "\n",
        "# --- Preview ---\n",
        "display(\n",
        "    fusion_df[\n",
        "        [\n",
        "            \"content.url1\",\n",
        "            \"content.url2\",\n",
        "            \"siamese_similarity\",\n",
        "            \"avg_entity_similarity\",\n",
        "            \"fused_similarity\",\n",
        "        ]\n",
        "    ].head()\n",
        ")\n",
        "\n",
        "# For final saving\n",
        "final_output = fusion_df\n"
      ],
      "metadata": {
        "id": "OYjx0Utp6tFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####  STEP 7: Pearson Correlation Analysis\n"
      ],
      "metadata": {
        "id": "Oe2TlxZD64aV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "#  STEP 7: Pearson Correlation Analysis\n",
        "# ================================================================\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 7: Pearson Correlation Analysis\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Use the latest unified dataframe from Step 5\n",
        "correlation_df = final_output.copy()\n",
        "\n",
        "# Identify available columns\n",
        "correlation_cols = [\n",
        "    \"entity_who_sim\", \"entity_what_sim\", \"entity_when_sim\",\n",
        "    \"entity_where_sim\", \"entity_why_sim\", \"entity_how_sim\",\n",
        "    \"avg_entity_similarity\", \"siamese_similarity\", \"fused_similarity\",\n",
        "]\n",
        "correlation_cols = [col for col in correlation_cols if col in correlation_df.columns]\n",
        "\n",
        "# --- Compute correlation matrix ---\n",
        "if correlation_cols:\n",
        "    correlation_matrix = correlation_df[correlation_cols].corr(method=\"pearson\")\n",
        "    print(\"\\nPearson Correlation Matrix:\")\n",
        "    print(correlation_matrix.round(3))\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No valid similarity columns found for correlation analysis.\")\n",
        "\n",
        "# --- Key correlations ---\n",
        "print(\"\\n\" + \"-\" * 60)\n",
        "print(\"Key Correlations:\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "def safe_corr(x, y):\n",
        "    \"\"\"Compute Pearson correlation safely.\"\"\"\n",
        "    try:\n",
        "        corr, p_val = pearsonr(\n",
        "            correlation_df[x].fillna(0).astype(float),\n",
        "            correlation_df[y].fillna(0).astype(float),\n",
        "        )\n",
        "        return corr, p_val\n",
        "    except Exception:\n",
        "        return np.nan, np.nan\n",
        "\n",
        "if \"avg_entity_similarity\" in correlation_df.columns and \"siamese_similarity\" in correlation_df.columns:\n",
        "    corr, p_val = safe_corr(\"avg_entity_similarity\", \"siamese_similarity\")\n",
        "    print(f\"Entity vs Siamese Similarity: r={corr:.4f}, p={p_val:.4e}\")\n",
        "\n",
        "if \"fused_similarity\" in correlation_df.columns and \"siamese_similarity\" in correlation_df.columns:\n",
        "    corr, p_val = safe_corr(\"fused_similarity\", \"siamese_similarity\")\n",
        "    print(f\"Fused vs Siamese Similarity: r={corr:.4f}, p={p_val:.4e}\")\n",
        "\n",
        "if \"fused_similarity\" in correlation_df.columns and \"avg_entity_similarity\" in correlation_df.columns:\n",
        "    corr, p_val = safe_corr(\"fused_similarity\", \"avg_entity_similarity\")\n",
        "    print(f\"Fused vs Entity Similarity: r={corr:.4f}, p={p_val:.4e}\")\n"
      ],
      "metadata": {
        "id": "tWSfv3ys639R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####  STEP 8: Save Results\n"
      ],
      "metadata": {
        "id": "-zqIQ--w7B1W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_df = final_output.copy()"
      ],
      "metadata": {
        "id": "nI3i6dKnQ-Lj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 8: Saving Results\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "final_columns = [\n",
        "    'content.url1', 'content.url2',\n",
        "    'content.title1', 'content.title2',\n",
        "    'content.title1.who', 'content.title1.what', 'content.title1.when',\n",
        "    'content.title1.where', 'content.title1.why', 'content.title1.how',\n",
        "    'content.title2.who', 'content.title2.what', 'content.title2.when',\n",
        "    'content.title2.where', 'content.title2.why', 'content.title2.how',\n",
        "    'entity_who_sim', 'entity_what_sim', 'entity_when_sim',\n",
        "    'entity_where_sim', 'entity_why_sim', 'entity_how_sim',\n",
        "    'avg_entity_similarity', 'siamese_similarity', 'fused_similarity'\n",
        "]\n",
        "\n",
        "final_columns = [c for c in final_columns if c in final_df.columns]\n",
        "\n",
        "# --- save results ---\n",
        "output_file = \"final_similarity_results.csv\"\n",
        "final_df[final_columns].to_csv(output_file, index=False)\n",
        "print(f\"‚úì Saved complete results to: {output_file}\")\n",
        "\n",
        "# --- save correlation matrix ---\n",
        "correlation_output = \"correlation_matrix.csv\"\n",
        "correlation_matrix.to_csv(correlation_output)\n",
        "print(f\"‚úì Saved correlation matrix to: {correlation_output}\")\n",
        "\n",
        "# --- save summary statistics (only existing numeric cols) ---\n",
        "summary_cols = [c for c in [\"avg_entity_similarity\", \"siamese_similarity\", \"fused_similarity\"]\n",
        "                if c in final_df.columns]\n",
        "if summary_cols:\n",
        "    summary_stats = final_df[summary_cols].describe()\n",
        "    summary_output = \"similarity_statistics.csv\"\n",
        "    summary_stats.to_csv(summary_output)\n",
        "    print(f\"‚úì Saved summary statistics to: {summary_output}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No similarity columns found for summary statistics.\")\n"
      ],
      "metadata": {
        "id": "Xo4oSunc7EiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####  STEP 9: Visualization and Analysis\n"
      ],
      "metadata": {
        "id": "xcPa6xJl7L1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 9: Summary Statistics & Analysis\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Display summary statistics\n",
        "print(\"\\nSimilarity Score Distribution:\")\n",
        "print(final_df[correlation_cols].describe().round(4))\n",
        "\n",
        "# Find top similar pairs\n",
        "print(\"\\n\" + \"-\"*60)\n",
        "print(\"Top 10 Most Similar Article Pairs (by Fused Similarity):\")\n",
        "print(\"-\"*60)\n",
        "top_similar = final_df.nlargest(10, 'fused_similarity')[\n",
        "    ['content.title1', 'content.title2', 'avg_entity_similarity',\n",
        "     'siamese_similarity', 'fused_similarity']\n",
        "]\n",
        "print(top_similar.to_string(index=False))\n",
        "\n",
        "# Find least similar pairs\n",
        "print(\"\\n\" + \"-\"*60)\n",
        "print(\"Top 10 Least Similar Article Pairs (by Fused Similarity):\")\n",
        "print(\"-\"*60)\n",
        "least_similar = final_df.nsmallest(10, 'fused_similarity')[\n",
        "    ['content.title1', 'content.title2', 'avg_entity_similarity',\n",
        "     'siamese_similarity', 'fused_similarity']\n",
        "]\n",
        "print(least_similar.to_string(index=False))\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úì Analysis Complete!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nGenerated files:\")\n",
        "print(f\"  1. {output_file}\")\n",
        "print(f\"  2. {correlation_output}\")\n",
        "print(f\"  3. {summary_output}\")"
      ],
      "metadata": {
        "id": "lcQf1fX-7J4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####  STEP 10: Quantitative Evaluation Metrics\n"
      ],
      "metadata": {
        "id": "gyNxqcdQ7q-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report,\n",
        "    precision_recall_curve, roc_curve, auc,\n",
        "    f1_score, precision_score, recall_score, accuracy_score\n",
        ")\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 10: Quantitative Evaluation Metrics\")\n",
        "print(\"=\"*60)\n"
      ],
      "metadata": {
        "id": "r-MQBF5C7nFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "#  Convert Continuous Scores to Binary Predictions\n",
        "# ================================================================\n",
        "\n",
        "def evaluate_at_threshold(y_true, y_scores, threshold):\n",
        "    \"\"\"Evaluate predictions at a specific threshold.\"\"\"\n",
        "    y_pred = (y_scores >= threshold).astype(int)\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
        "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
        "\n",
        "    return {\n",
        "        'threshold': threshold,\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1\n",
        "    }"
      ],
      "metadata": {
        "id": "mvQRLM9E8bYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "#  STEP 10: Use Real Ground Truth Labels\n",
        "# ================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 10: Using Real Ground Truth Labels (content.similarity)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "if \"content.similarity\" in final_df.columns:\n",
        "    # Use 0.5 as threshold to convert similarity into binary labels\n",
        "    final_df[\"ground_truth\"] = (final_df[\"content.similarity\"] >= 0.5).astype(int)\n",
        "    print(\"‚úÖ Ground truth labels loaded from 'content.similarity'.\")\n",
        "else:\n",
        "    raise ValueError(\"‚ùå 'content.similarity' column not found in dataset.\")\n",
        "\n",
        "print(f\"Total labelled pairs: {len(final_df)}\")\n",
        "print(final_df[[\"content.similarity\", \"fused_similarity\", \"ground_truth\"]].head())\n"
      ],
      "metadata": {
        "id": "X-Nf8lVx8nNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Test multiple thresholds\n",
        "thresholds_to_test = np.arange(0.1, 1.0, 0.05)\n",
        "y_true = final_df['ground_truth'].values\n",
        "\n",
        "# Evaluate each similarity measure\n",
        "similarity_measures = {\n",
        "    'Entity Similarity': 'avg_entity_similarity',\n",
        "    'Siamese Similarity': 'siamese_similarity',\n",
        "    'Fused Similarity': 'fused_similarity'\n",
        "}\n",
        "\n",
        "results_by_measure = {}\n",
        "\n",
        "for measure_name, measure_col in similarity_measures.items():\n",
        "    if measure_col in final_df.columns:\n",
        "        y_scores = final_df[measure_col].fillna(0).values\n",
        "\n",
        "        # Evaluate at different thresholds\n",
        "        threshold_results = []\n",
        "        for thresh in thresholds_to_test:\n",
        "            metrics = evaluate_at_threshold(y_true, y_scores, thresh)\n",
        "            threshold_results.append(metrics)\n",
        "\n",
        "        results_by_measure[measure_name] = {\n",
        "            'scores': y_scores,\n",
        "            'threshold_results': pd.DataFrame(threshold_results)\n",
        "        }"
      ],
      "metadata": {
        "id": "vW_yVavf8fCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"-\"*60)\n",
        "print(\"Optimal Thresholds (Maximum F1 Score):\")\n",
        "print(\"-\"*60)\n",
        "\n",
        "optimal_thresholds = {}\n",
        "\n",
        "for measure_name, data in results_by_measure.items():\n",
        "    df_thresh = data['threshold_results']\n",
        "    optimal_idx = df_thresh['f1'].idxmax()\n",
        "    optimal_row = df_thresh.iloc[optimal_idx]\n",
        "    optimal_thresholds[measure_name] = optimal_row['threshold']\n",
        "\n",
        "    print(f\"\\n{measure_name}:\")\n",
        "    print(f\"  Optimal Threshold: {optimal_row['threshold']:.3f}\")\n",
        "    print(f\"  Accuracy:  {optimal_row['accuracy']:.4f}\")\n",
        "    print(f\"  Precision: {optimal_row['precision']:.4f}\")\n",
        "    print(f\"  Recall:    {optimal_row['recall']:.4f}\")\n",
        "    print(f\"  F1 Score:  {optimal_row['f1']:.4f}\")"
      ],
      "metadata": {
        "id": "IGV5FtlO8qns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "######   Confusion Matrix\n",
        "\n"
      ],
      "metadata": {
        "id": "a0C1cSeH7wOy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Generating Confusion Matrices...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "fig.suptitle('Confusion Matrices at Optimal Thresholds', fontsize=16, fontweight='bold')\n",
        "\n",
        "for idx, (measure_name, measure_col) in enumerate(similarity_measures.items()):\n",
        "    if measure_col in final_df.columns:\n",
        "        y_scores = final_df[measure_col].fillna(0).values\n",
        "        threshold = optimal_thresholds[measure_name]\n",
        "        y_pred = (y_scores >= threshold).astype(int)\n",
        "\n",
        "        # Compute confusion matrix\n",
        "        cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "        # Plot\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                   cbar=False, ax=axes[idx],\n",
        "                   xticklabels=['Not Similar', 'Similar'],\n",
        "                   yticklabels=['Not Similar', 'Similar'])\n",
        "        axes[idx].set_title(f'{measure_name}\\n(Threshold: {threshold:.3f})')\n",
        "        axes[idx].set_ylabel('True Label')\n",
        "        axes[idx].set_xlabel('Predicted Label')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('confusion_matrices.png', dpi=300, bbox_inches='tight')\n",
        "print(\"‚úì Saved: confusion_matrices.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TzeVP-Gc78xl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ================================================================\n",
        "#  Precision-Recall Curves\n",
        "# ================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Generating Precision-Recall Curves...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "for measure_name, data in results_by_measure.items():\n",
        "    y_scores = data['scores']\n",
        "    precision, recall, _ = precision_recall_curve(y_true, y_scores)\n",
        "    pr_auc = auc(recall, precision)\n",
        "\n",
        "    ax.plot(recall, precision, label=f'{measure_name} (AUC={pr_auc:.3f})', linewidth=2)\n",
        "\n",
        "ax.set_xlabel('Recall', fontsize=12)\n",
        "ax.set_ylabel('Precision', fontsize=12)\n",
        "ax.set_title('Precision-Recall Curves', fontsize=14, fontweight='bold')\n",
        "ax.legend(loc='best', fontsize=10)\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.set_xlim([0, 1])\n",
        "ax.set_ylim([0, 1])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('precision_recall_curves.png', dpi=300, bbox_inches='tight')\n",
        "print(\"‚úì Saved: precision_recall_curves.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YtIcwCeJ8w4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ================================================================\n",
        "#  ROC Curves\n",
        "# ================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Generating ROC Curves...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "for measure_name, data in results_by_measure.items():\n",
        "    y_scores = data['scores']\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    ax.plot(fpr, tpr, label=f'{measure_name} (AUC={roc_auc:.3f})', linewidth=2)\n",
        "\n",
        "# Plot diagonal line\n",
        "ax.plot([0, 1], [0, 1], 'k--', label='Random Classifier', linewidth=1)\n",
        "\n",
        "ax.set_xlabel('False Positive Rate', fontsize=12)\n",
        "ax.set_ylabel('True Positive Rate', fontsize=12)\n",
        "ax.set_title('ROC Curves', fontsize=14, fontweight='bold')\n",
        "ax.legend(loc='lower right', fontsize=10)\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.set_xlim([0, 1])\n",
        "ax.set_ylim([0, 1])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('roc_curves.png', dpi=300, bbox_inches='tight')\n",
        "print(\"‚úì Saved: roc_curves.png\")\n",
        "plt.show()\n",
        "\n",
        "# ============"
      ],
      "metadata": {
        "id": "rg5nFDOj82N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "#  F1 Score vs Threshold Curves\n",
        "# ================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Generating F1 Score vs Threshold Curves...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "for measure_name, data in results_by_measure.items():\n",
        "    df_thresh = data['threshold_results']\n",
        "    ax.plot(df_thresh['threshold'], df_thresh['f1'],\n",
        "           label=measure_name, linewidth=2, marker='o', markersize=3)\n",
        "\n",
        "ax.set_xlabel('Threshold', fontsize=12)\n",
        "ax.set_ylabel('F1 Score', fontsize=12)\n",
        "ax.set_title('F1 Score vs Threshold', fontsize=14, fontweight='bold')\n",
        "ax.legend(loc='best', fontsize=10)\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.set_xlim([0, 1])\n",
        "ax.set_ylim([0, 1])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('f1_vs_threshold.png', dpi=300, bbox_inches='tight')\n",
        "print(\"‚úì Saved: f1_vs_threshold.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uu_uAc1T87RE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "#  Precision, Recall, F1 vs Threshold (Combined)\n",
        "# ================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Generating Combined Metrics vs Threshold...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "fig.suptitle('Metrics vs Threshold for Different Similarity Measures',\n",
        "             fontsize=16, fontweight='bold')\n",
        "\n",
        "metric_names = ['precision', 'recall', 'f1']\n",
        "metric_labels = ['Precision', 'Recall', 'F1 Score']\n",
        "\n",
        "for idx, (metric, label) in enumerate(zip(metric_names, metric_labels)):\n",
        "    for measure_name, data in results_by_measure.items():\n",
        "        df_thresh = data['threshold_results']\n",
        "        axes[idx].plot(df_thresh['threshold'], df_thresh[metric],\n",
        "                      label=measure_name, linewidth=2, marker='o', markersize=3)\n",
        "\n",
        "    axes[idx].set_xlabel('Threshold', fontsize=12)\n",
        "    axes[idx].set_ylabel(label, fontsize=12)\n",
        "    axes[idx].set_title(f'{label} vs Threshold', fontsize=12, fontweight='bold')\n",
        "    axes[idx].legend(loc='best', fontsize=9)\n",
        "    axes[idx].grid(True, alpha=0.3)\n",
        "    axes[idx].set_xlim([0, 1])\n",
        "    axes[idx].set_ylim([0, 1])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('metrics_vs_threshold.png', dpi=300, bbox_inches='tight')\n",
        "print(\"‚úì Saved: metrics_vs_threshold.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "d9bH3EAX9GWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Classification Reports at Optimal Thresholds:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "df_eval = final_df if 'fused_similarity' in final_df.columns else result_df.copy()\n",
        "\n",
        "for measure_name, measure_col in similarity_measures.items():\n",
        "    if measure_col in df_eval.columns:\n",
        "        y_scores = df_eval[measure_col].fillna(0).values\n",
        "        threshold = optimal_thresholds[measure_name]\n",
        "        y_pred = (y_scores >= threshold).astype(int)\n",
        "\n",
        "        print(f\"\\n{measure_name} (Threshold: {threshold:.3f}):\")\n",
        "        print(\"-\" * 60)\n",
        "        print(classification_report(\n",
        "            y_true, y_pred,\n",
        "            labels=[0, 1],  # <- ensures consistent output\n",
        "            target_names=['Not Similar', 'Similar'],\n",
        "            digits=4,\n",
        "            zero_division=0\n",
        "        ))\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Skipping {measure_name}: column '{measure_col}' not found.\")\n"
      ],
      "metadata": {
        "id": "NeDdQFAA9MB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Comparative Performance Summary:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Pick correct dataframe dynamically\n",
        "df_eval = final_df if 'fused_similarity' in final_df.columns else result_df.copy()\n",
        "\n",
        "performance_data = []\n",
        "\n",
        "for measure_name, measure_col in similarity_measures.items():\n",
        "    if measure_col not in df_eval.columns:\n",
        "        print(f\"‚ö†Ô∏è Skipping '{measure_name}' ‚Äî missing column '{measure_col}'.\")\n",
        "        continue\n",
        "\n",
        "    y_scores = df_eval[measure_col].fillna(0).values\n",
        "    threshold = optimal_thresholds.get(measure_name, np.median(y_scores))\n",
        "    y_pred = (y_scores >= threshold).astype(int)\n",
        "\n",
        "    # Compute metrics\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
        "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
        "\n",
        "    # Compute AUC scores\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    prec, rec, _ = precision_recall_curve(y_true, y_scores)\n",
        "    pr_auc = auc(rec, prec)\n",
        "\n",
        "    performance_data.append({\n",
        "        \"Measure\": measure_name,\n",
        "        \"Optimal Threshold\": threshold,\n",
        "        \"Accuracy\": accuracy,\n",
        "        \"Precision\": precision,\n",
        "        \"Recall\": recall,\n",
        "        \"F1\": f1,\n",
        "        \"ROC-AUC\": roc_auc,\n",
        "        \"PR-AUC\": pr_auc\n",
        "    })\n",
        "\n",
        "# --- Build dataframe safely ---\n",
        "if len(performance_data) == 0:\n",
        "    print(\"‚ùå No valid similarity columns found. Please check final_df contents.\")\n",
        "    print(\"Available columns:\", df_eval.columns.tolist())\n",
        "else:\n",
        "    performance_df = pd.DataFrame(performance_data)\n",
        "    print(\"\\n\", performance_df.to_string(index=False))\n",
        "    performance_df.to_csv(\"performance_comparison.csv\", index=False)\n",
        "    print(\"\\n‚úì Saved: performance_comparison.csv\")\n"
      ],
      "metadata": {
        "id": "2_ez1PWP9NNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "#  Summary\n",
        "# ================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Key Findings:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "best_idx = performance_df[\"F1\"].idxmax()\n",
        "best_measure = performance_df.iloc[best_idx]\n",
        "\n",
        "print(f\"\\nüèÜ Best Performing Measure: {best_measure['Measure']}\")\n",
        "print(f\"  F1 Score : {best_measure['F1']:.4f}\")\n",
        "print(f\"  Accuracy : {best_measure['Accuracy']:.4f}\")\n",
        "print(f\"  Precision: {best_measure['Precision']:.4f}\")\n",
        "print(f\"  Recall   : {best_measure['Recall']:.4f}\")\n",
        "print(f\"  ROC-AUC  : {best_measure['ROC-AUC']:.4f}\")\n",
        "print(f\"  PR-AUC   : {best_measure['PR-AUC']:.4f}\")\n",
        "print(\"\\n\" + \"=\"*60)\n"
      ],
      "metadata": {
        "id": "ofAkvFbq9WVN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}